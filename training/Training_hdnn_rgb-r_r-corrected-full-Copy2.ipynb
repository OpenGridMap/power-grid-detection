{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpadlyol/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpadlyol/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5110)\n",
      "C:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.hdnn import hdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=100\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 3)\n",
    "\n",
    "name = 'hdnn_relu_140_rgb_corrected_full_lr_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "Compiling conv2d layer: stage 1 block 1...\n",
      "Compiling conv2d layer: stage 2 block 1...\n",
      "Compiling conv2d layer: stage 3 block 1...\n",
      "Creating hybrid block with 3 conv2d blocks: stage 4\n",
      "Compiling conv2d layer: stage 4 block 1...\n",
      "Compiling conv2d layer: stage 4 block 2...\n",
      "Compiling conv2d layer: stage 4 block 3...\n",
      "Merging hybrid blocks : stage 4\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "C1_1 (Convolution2D)             (None, 134, 134, 84)  12432       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 134, 134, 84)  0           C1_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M1_1 (MaxPooling2D)              (None, 67, 67, 84)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C2_1 (Convolution2D)             (None, 64, 64, 84)    112980      M1_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 64, 64, 84)    0           C2_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M2_1 (MaxPooling2D)              (None, 32, 32, 84)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C3_1 (Convolution2D)             (None, 29, 29, 54)    72630       M2_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 29, 29, 54)    0           C3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M3_1 (MaxPooling2D)              (None, 14, 14, 54)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C4_1 (Convolution2D)             (None, 6, 6, 54)      46710       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "C4_2 (Convolution2D)             (None, 6, 6, 20)      17300       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "C4_3 (Convolution2D)             (None, 5, 5, 10)      19450       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 6, 6, 54)      0           C4_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 6, 6, 20)      0           C4_2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 5, 5, 10)      0           C4_3[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M4_1 (MaxPooling2D)              (None, 3, 3, 54)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "M4_2 (MaxPooling2D)              (None, 3, 3, 20)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "M4_3 (MaxPooling2D)              (None, 3, 3, 10)      0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 3, 3, 84)      0           M4_1[0][0]                       \n",
      "                                                                   M4_2[0][0]                       \n",
      "                                                                   M4_3[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 756)           0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 300)           227100      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             602         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 2)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 509,204\n",
      "Trainable params: 509,204\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = hdnn(input_shape=input_shape, activation_fn='relu', init='he_normal', l1=l1, l2=l2, weights='hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5')\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=True)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = config.corrected_train_data_file\n",
    "validation_set_file = config.corrected_validation_data_file\n",
    "test_set_file = config.corrected_test_data_file\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9870Epoch 00000: val_loss improved from inf to 0.06272, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 1456s - loss: 0.0652 - acc: 0.9870 - val_loss: 0.0627 - val_acc: 0.9876\n",
      "Epoch 2/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9877Epoch 00001: val_loss improved from 0.06272 to 0.05966, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 730s - loss: 0.0627 - acc: 0.9877 - val_loss: 0.0597 - val_acc: 0.9885\n",
      "Epoch 3/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9883Epoch 00002: val_loss improved from 0.05966 to 0.05827, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 737s - loss: 0.0613 - acc: 0.9882 - val_loss: 0.0583 - val_acc: 0.9892\n",
      "Epoch 4/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9884Epoch 00003: val_loss improved from 0.05827 to 0.05708, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0602 - acc: 0.9884 - val_loss: 0.0571 - val_acc: 0.9893\n",
      "Epoch 5/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9887Epoch 00004: val_loss improved from 0.05708 to 0.05618, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0592 - acc: 0.9886 - val_loss: 0.0562 - val_acc: 0.9900\n",
      "Epoch 6/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9889Epoch 00005: val_loss improved from 0.05618 to 0.05579, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0582 - acc: 0.9889 - val_loss: 0.0558 - val_acc: 0.9902\n",
      "Epoch 7/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9891Epoch 00006: val_loss improved from 0.05579 to 0.05542, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0575 - acc: 0.9891 - val_loss: 0.0554 - val_acc: 0.9898\n",
      "Epoch 8/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9894Epoch 00007: val_loss improved from 0.05542 to 0.05485, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 749s - loss: 0.0567 - acc: 0.9894 - val_loss: 0.0548 - val_acc: 0.9899\n",
      "Epoch 9/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9896Epoch 00008: val_loss improved from 0.05485 to 0.05416, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0559 - acc: 0.9896 - val_loss: 0.0542 - val_acc: 0.9898\n",
      "Epoch 10/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9900Epoch 00009: val_loss improved from 0.05416 to 0.05392, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0553 - acc: 0.9899 - val_loss: 0.0539 - val_acc: 0.9899\n",
      "Epoch 11/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9901Epoch 00010: val_loss improved from 0.05392 to 0.05358, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0546 - acc: 0.9901 - val_loss: 0.0536 - val_acc: 0.9900\n",
      "Epoch 12/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9903Epoch 00011: val_loss improved from 0.05358 to 0.05331, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0539 - acc: 0.9903 - val_loss: 0.0533 - val_acc: 0.9902\n",
      "Epoch 13/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9903Epoch 00012: val_loss improved from 0.05331 to 0.05199, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0532 - acc: 0.9903 - val_loss: 0.0520 - val_acc: 0.9907\n",
      "Epoch 14/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9906Epoch 00013: val_loss improved from 0.05199 to 0.05168, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0526 - acc: 0.9906 - val_loss: 0.0517 - val_acc: 0.9907\n",
      "Epoch 15/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9906Epoch 00014: val_loss improved from 0.05168 to 0.05121, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 745s - loss: 0.0520 - acc: 0.9906 - val_loss: 0.0512 - val_acc: 0.9907\n",
      "Epoch 16/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9909Epoch 00015: val_loss improved from 0.05121 to 0.05049, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 753s - loss: 0.0514 - acc: 0.9909 - val_loss: 0.0505 - val_acc: 0.9914\n",
      "Epoch 17/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9909Epoch 00016: val_loss improved from 0.05049 to 0.05010, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 748s - loss: 0.0508 - acc: 0.9909 - val_loss: 0.0501 - val_acc: 0.9914\n",
      "Epoch 18/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9912Epoch 00017: val_loss improved from 0.05010 to 0.04971, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0503 - acc: 0.9912 - val_loss: 0.0497 - val_acc: 0.9914\n",
      "Epoch 19/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9914Epoch 00018: val_loss improved from 0.04971 to 0.04931, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0498 - acc: 0.9914 - val_loss: 0.0493 - val_acc: 0.9915\n",
      "Epoch 20/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9915Epoch 00019: val_loss improved from 0.04931 to 0.04893, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0493 - acc: 0.9915 - val_loss: 0.0489 - val_acc: 0.9915\n",
      "Epoch 21/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9916Epoch 00020: val_loss improved from 0.04893 to 0.04869, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0488 - acc: 0.9916 - val_loss: 0.0487 - val_acc: 0.9915\n",
      "Epoch 22/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9917Epoch 00021: val_loss improved from 0.04869 to 0.04794, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0483 - acc: 0.9917 - val_loss: 0.0479 - val_acc: 0.9918\n",
      "Epoch 23/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9917Epoch 00022: val_loss improved from 0.04794 to 0.04755, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 744s - loss: 0.0478 - acc: 0.9916 - val_loss: 0.0475 - val_acc: 0.9918\n",
      "Epoch 24/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9919Epoch 00023: val_loss improved from 0.04755 to 0.04710, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 731s - loss: 0.0474 - acc: 0.9919 - val_loss: 0.0471 - val_acc: 0.9921\n",
      "Epoch 25/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9920Epoch 00024: val_loss improved from 0.04710 to 0.04671, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0469 - acc: 0.9920 - val_loss: 0.0467 - val_acc: 0.9922\n",
      "Epoch 26/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9921Epoch 00025: val_loss improved from 0.04671 to 0.04643, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0465 - acc: 0.9921 - val_loss: 0.0464 - val_acc: 0.9921\n",
      "Epoch 27/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9921Epoch 00026: val_loss improved from 0.04643 to 0.04606, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 728s - loss: 0.0461 - acc: 0.9921 - val_loss: 0.0461 - val_acc: 0.9921\n",
      "Epoch 28/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9923Epoch 00027: val_loss improved from 0.04606 to 0.04591, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0457 - acc: 0.9923 - val_loss: 0.0459 - val_acc: 0.9923\n",
      "Epoch 29/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9923Epoch 00028: val_loss improved from 0.04591 to 0.04576, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0453 - acc: 0.9923 - val_loss: 0.0458 - val_acc: 0.9923\n",
      "Epoch 30/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9925Epoch 00029: val_loss improved from 0.04576 to 0.04504, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 740s - loss: 0.0449 - acc: 0.9924 - val_loss: 0.0450 - val_acc: 0.9924\n",
      "Epoch 31/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9926Epoch 00030: val_loss improved from 0.04504 to 0.04445, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0445 - acc: 0.9926 - val_loss: 0.0445 - val_acc: 0.9921\n",
      "Epoch 32/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9927Epoch 00031: val_loss improved from 0.04445 to 0.04376, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0442 - acc: 0.9926 - val_loss: 0.0438 - val_acc: 0.9925\n",
      "Epoch 33/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9926Epoch 00032: val_loss did not improve\n",
      "65504/65504 [==============================] - 738s - loss: 0.0438 - acc: 0.9926 - val_loss: 0.0438 - val_acc: 0.9923\n",
      "Epoch 34/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9928Epoch 00033: val_loss improved from 0.04376 to 0.04332, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 737s - loss: 0.0435 - acc: 0.9928 - val_loss: 0.0433 - val_acc: 0.9925\n",
      "Epoch 35/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9929Epoch 00034: val_loss improved from 0.04332 to 0.04278, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 748s - loss: 0.0432 - acc: 0.9929 - val_loss: 0.0428 - val_acc: 0.9928\n",
      "Epoch 36/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9931Epoch 00035: val_loss improved from 0.04278 to 0.04270, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 739s - loss: 0.0428 - acc: 0.9931 - val_loss: 0.0427 - val_acc: 0.9926\n",
      "Epoch 37/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9931Epoch 00036: val_loss improved from 0.04270 to 0.04212, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 739s - loss: 0.0425 - acc: 0.9931 - val_loss: 0.0421 - val_acc: 0.9930\n",
      "Epoch 38/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9932Epoch 00037: val_loss improved from 0.04212 to 0.04206, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0421 - acc: 0.9932 - val_loss: 0.0421 - val_acc: 0.9931\n",
      "Epoch 39/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9932Epoch 00038: val_loss improved from 0.04206 to 0.04183, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0418 - acc: 0.9932 - val_loss: 0.0418 - val_acc: 0.9930\n",
      "Epoch 40/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9932Epoch 00039: val_loss improved from 0.04183 to 0.04182, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 737s - loss: 0.0415 - acc: 0.9932 - val_loss: 0.0418 - val_acc: 0.9930\n",
      "Epoch 41/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9933Epoch 00040: val_loss improved from 0.04182 to 0.04121, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 1470s - loss: 0.0412 - acc: 0.9933 - val_loss: 0.0412 - val_acc: 0.9932\n",
      "Epoch 42/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9933Epoch 00041: val_loss improved from 0.04121 to 0.04097, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 735s - loss: 0.0409 - acc: 0.9933 - val_loss: 0.0410 - val_acc: 0.9932\n",
      "Epoch 43/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9934Epoch 00042: val_loss improved from 0.04097 to 0.04084, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 737s - loss: 0.0406 - acc: 0.9934 - val_loss: 0.0408 - val_acc: 0.9934\n",
      "Epoch 44/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9934Epoch 00043: val_loss improved from 0.04084 to 0.04073, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 738s - loss: 0.0403 - acc: 0.9934 - val_loss: 0.0407 - val_acc: 0.9932\n",
      "Epoch 45/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9935Epoch 00044: val_loss improved from 0.04073 to 0.04047, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 738s - loss: 0.0400 - acc: 0.9935 - val_loss: 0.0405 - val_acc: 0.9934\n",
      "Epoch 46/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9936Epoch 00045: val_loss improved from 0.04047 to 0.04014, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 751s - loss: 0.0398 - acc: 0.9936 - val_loss: 0.0401 - val_acc: 0.9935\n",
      "Epoch 47/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9937Epoch 00046: val_loss improved from 0.04014 to 0.04009, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 744s - loss: 0.0394 - acc: 0.9937 - val_loss: 0.0401 - val_acc: 0.9935\n",
      "Epoch 48/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9937Epoch 00047: val_loss improved from 0.04009 to 0.03987, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 740s - loss: 0.0392 - acc: 0.9937 - val_loss: 0.0399 - val_acc: 0.9936\n",
      "Epoch 49/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9938Epoch 00048: val_loss improved from 0.03987 to 0.03966, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 739s - loss: 0.0389 - acc: 0.9938 - val_loss: 0.0397 - val_acc: 0.9936\n",
      "Epoch 50/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9939Epoch 00049: val_loss improved from 0.03966 to 0.03942, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 735s - loss: 0.0386 - acc: 0.9938 - val_loss: 0.0394 - val_acc: 0.9935\n",
      "Epoch 51/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9938Epoch 00050: val_loss improved from 0.03942 to 0.03926, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0383 - acc: 0.9938 - val_loss: 0.0393 - val_acc: 0.9936\n",
      "Epoch 52/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9939Epoch 00051: val_loss improved from 0.03926 to 0.03909, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0381 - acc: 0.9939 - val_loss: 0.0391 - val_acc: 0.9937\n",
      "Epoch 53/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9938Epoch 00052: val_loss improved from 0.03909 to 0.03889, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0378 - acc: 0.9938 - val_loss: 0.0389 - val_acc: 0.9937\n",
      "Epoch 54/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9939Epoch 00053: val_loss improved from 0.03889 to 0.03872, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0376 - acc: 0.9939 - val_loss: 0.0387 - val_acc: 0.9936\n",
      "Epoch 55/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9940Epoch 00054: val_loss improved from 0.03872 to 0.03861, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 732s - loss: 0.0373 - acc: 0.9939 - val_loss: 0.0386 - val_acc: 0.9936\n",
      "Epoch 56/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9940Epoch 00055: val_loss improved from 0.03861 to 0.03844, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0371 - acc: 0.9940 - val_loss: 0.0384 - val_acc: 0.9936\n",
      "Epoch 57/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9941Epoch 00056: val_loss improved from 0.03844 to 0.03829, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0368 - acc: 0.9941 - val_loss: 0.0383 - val_acc: 0.9937\n",
      "Epoch 58/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9941Epoch 00057: val_loss improved from 0.03829 to 0.03816, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0366 - acc: 0.9941 - val_loss: 0.0382 - val_acc: 0.9938\n",
      "Epoch 59/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9942Epoch 00058: val_loss improved from 0.03816 to 0.03807, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 735s - loss: 0.0363 - acc: 0.9942 - val_loss: 0.0381 - val_acc: 0.9938\n",
      "Epoch 60/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9942Epoch 00059: val_loss improved from 0.03807 to 0.03804, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 735s - loss: 0.0361 - acc: 0.9942 - val_loss: 0.0380 - val_acc: 0.9936\n",
      "Epoch 61/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9942Epoch 00060: val_loss improved from 0.03804 to 0.03783, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 735s - loss: 0.0359 - acc: 0.9942 - val_loss: 0.0378 - val_acc: 0.9936\n",
      "Epoch 62/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9943Epoch 00061: val_loss improved from 0.03783 to 0.03773, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0357 - acc: 0.9943 - val_loss: 0.0377 - val_acc: 0.9936\n",
      "Epoch 63/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9943Epoch 00062: val_loss improved from 0.03773 to 0.03761, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0355 - acc: 0.9943 - val_loss: 0.0376 - val_acc: 0.9936\n",
      "Epoch 64/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9944Epoch 00063: val_loss did not improve\n",
      "65504/65504 [==============================] - 733s - loss: 0.0353 - acc: 0.9944 - val_loss: 0.0378 - val_acc: 0.9938\n",
      "Epoch 65/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9945Epoch 00064: val_loss improved from 0.03761 to 0.03740, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 775s - loss: 0.0350 - acc: 0.9945 - val_loss: 0.0374 - val_acc: 0.9937\n",
      "Epoch 66/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9945Epoch 00065: val_loss improved from 0.03740 to 0.03738, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 733s - loss: 0.0348 - acc: 0.9945 - val_loss: 0.0374 - val_acc: 0.9937\n",
      "Epoch 67/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9946Epoch 00066: val_loss improved from 0.03738 to 0.03730, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0346 - acc: 0.9946 - val_loss: 0.0373 - val_acc: 0.9938\n",
      "Epoch 68/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9946Epoch 00067: val_loss improved from 0.03730 to 0.03698, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 734s - loss: 0.0344 - acc: 0.9946 - val_loss: 0.0370 - val_acc: 0.9938\n",
      "Epoch 69/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9946Epoch 00068: val_loss did not improve\n",
      "65504/65504 [==============================] - 734s - loss: 0.0342 - acc: 0.9945 - val_loss: 0.0372 - val_acc: 0.9937\n",
      "Epoch 70/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9946Epoch 00069: val_loss did not improve\n",
      "65504/65504 [==============================] - 740s - loss: 0.0340 - acc: 0.9946 - val_loss: 0.0371 - val_acc: 0.9937\n",
      "Epoch 71/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9946Epoch 00070: val_loss improved from 0.03698 to 0.03665, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 739s - loss: 0.0338 - acc: 0.9946 - val_loss: 0.0367 - val_acc: 0.9937\n",
      "Epoch 72/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9947Epoch 00071: val_loss improved from 0.03665 to 0.03654, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 739s - loss: 0.0336 - acc: 0.9947 - val_loss: 0.0365 - val_acc: 0.9940\n",
      "Epoch 73/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9947Epoch 00072: val_loss improved from 0.03654 to 0.03644, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 744s - loss: 0.0334 - acc: 0.9947 - val_loss: 0.0364 - val_acc: 0.9937\n",
      "Epoch 74/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9948Epoch 00073: val_loss improved from 0.03644 to 0.03642, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 745s - loss: 0.0332 - acc: 0.9948 - val_loss: 0.0364 - val_acc: 0.9937\n",
      "Epoch 75/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9949Epoch 00074: val_loss improved from 0.03642 to 0.03615, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 738s - loss: 0.0330 - acc: 0.9948 - val_loss: 0.0361 - val_acc: 0.9941\n",
      "Epoch 76/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9949Epoch 00075: val_loss did not improve\n",
      "65504/65504 [==============================] - 734s - loss: 0.0328 - acc: 0.9949 - val_loss: 0.0363 - val_acc: 0.9937\n",
      "Epoch 77/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9949Epoch 00076: val_loss improved from 0.03615 to 0.03604, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 736s - loss: 0.0326 - acc: 0.9949 - val_loss: 0.0360 - val_acc: 0.9940\n",
      "Epoch 78/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9950Epoch 00077: val_loss did not improve\n",
      "65504/65504 [==============================] - 735s - loss: 0.0324 - acc: 0.9949 - val_loss: 0.0366 - val_acc: 0.9936\n",
      "Epoch 79/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9950Epoch 00078: val_loss improved from 0.03604 to 0.03582, saving model to ./hdnn_relu_140_rgb_corrected_full_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 737s - loss: 0.0322 - acc: 0.9950 - val_loss: 0.0358 - val_acc: 0.9939\n",
      "Epoch 80/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9951Epoch 00079: val_loss did not improve\n",
      "65504/65504 [==============================] - 738s - loss: 0.0321 - acc: 0.9950 - val_loss: 0.0360 - val_acc: 0.9938\n",
      "Epoch 81/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9951Epoch 00080: val_loss did not improve\n",
      "65504/65504 [==============================] - 743s - loss: 0.0319 - acc: 0.9951 - val_loss: 0.0396 - val_acc: 0.9919\n",
      "Epoch 82/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9951Epoch 00081: val_loss did not improve\n",
      "65504/65504 [==============================] - 735s - loss: 0.0317 - acc: 0.9951 - val_loss: 0.0394 - val_acc: 0.9920\n",
      "Epoch 83/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9951Epoch 00082: val_loss did not improve\n",
      "65504/65504 [==============================] - 750s - loss: 0.0315 - acc: 0.9951 - val_loss: 0.0397 - val_acc: 0.9917\n",
      "Epoch 84/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9952Epoch 00083: val_loss did not improve\n",
      "65504/65504 [==============================] - 744s - loss: 0.0313 - acc: 0.9952 - val_loss: 0.0393 - val_acc: 0.9918\n",
      "Epoch 85/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9952Epoch 00084: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0311 - acc: 0.9952 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "Epoch 86/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9953Epoch 00085: val_loss did not improve\n",
      "65504/65504 [==============================] - 747s - loss: 0.0310 - acc: 0.9953 - val_loss: 0.0401 - val_acc: 0.9916\n",
      "Epoch 87/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9953Epoch 00086: val_loss did not improve\n",
      "65504/65504 [==============================] - 735s - loss: 0.0308 - acc: 0.9953 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "Epoch 88/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9954Epoch 00087: val_loss did not improve\n",
      "65504/65504 [==============================] - 736s - loss: 0.0306 - acc: 0.9954 - val_loss: 0.0401 - val_acc: 0.9917\n",
      "Epoch 89/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9954Epoch 00088: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0304 - acc: 0.9954 - val_loss: 0.0401 - val_acc: 0.9918\n",
      "Epoch 90/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9954Epoch 00089: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0303 - acc: 0.9954 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "Epoch 91/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9954Epoch 00090: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0301 - acc: 0.9954 - val_loss: 0.0418 - val_acc: 0.9909\n",
      "Epoch 92/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9955Epoch 00091: val_loss did not improve\n",
      "65504/65504 [==============================] - 738s - loss: 0.0299 - acc: 0.9955 - val_loss: 0.0412 - val_acc: 0.9911\n",
      "Epoch 93/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9956Epoch 00092: val_loss did not improve\n",
      "65504/65504 [==============================] - 738s - loss: 0.0297 - acc: 0.9955 - val_loss: 0.0425 - val_acc: 0.9908\n",
      "Epoch 94/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9955Epoch 00093: val_loss did not improve\n",
      "65504/65504 [==============================] - 735s - loss: 0.0296 - acc: 0.9955 - val_loss: 0.0416 - val_acc: 0.9909\n",
      "Epoch 95/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9957Epoch 00094: val_loss did not improve\n",
      "65504/65504 [==============================] - 734s - loss: 0.0294 - acc: 0.9956 - val_loss: 0.0420 - val_acc: 0.9909\n",
      "Epoch 96/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9957Epoch 00095: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0292 - acc: 0.9957 - val_loss: 0.0418 - val_acc: 0.9909\n",
      "Epoch 97/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9958Epoch 00096: val_loss did not improve\n",
      "65504/65504 [==============================] - 736s - loss: 0.0291 - acc: 0.9957 - val_loss: 0.0418 - val_acc: 0.9910\n",
      "Epoch 98/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9958Epoch 00097: val_loss did not improve\n",
      "65504/65504 [==============================] - 736s - loss: 0.0289 - acc: 0.9958 - val_loss: 0.0418 - val_acc: 0.9909\n",
      "Epoch 99/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9959Epoch 00098: val_loss did not improve\n",
      "65504/65504 [==============================] - 739s - loss: 0.0287 - acc: 0.9959 - val_loss: 0.0423 - val_acc: 0.9908\n",
      "Epoch 100/100\n",
      "65472/65504 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9959Epoch 00099: val_loss did not improve\n",
      "65504/65504 [==============================] - 737s - loss: 0.0286 - acc: 0.9959 - val_loss: 0.0422 - val_acc: 0.9908\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=2)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
