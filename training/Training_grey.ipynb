{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.cnn3_with_normalization import cnn_w_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_epochs=500\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 1)\n",
    "\n",
    "name = 'cnn_140_grey_lr_%f_nesterov_3' % lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 6400        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    204864      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    36928       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20764546\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "model = cnn_w_normalization(input_shape=input_shape)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=1., clipvalue=0.5, nesterov=True)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "csv_logger = CSVLogger('%s_training.log' % name)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('cnn_140_grey_lr_0.070000_nesterov_training_weights_best.hdf5')\n",
    "# model.load_weights('cnn_140_grey_lr_0.035000_nesterov_1_training_weights_best.hdf5')\n",
    "model.load_weights('cnn_140_grey_lr_0.010000_nesterov_2_training_weights_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_data_gen = DataGenerator(dataset_file=config.train_data_file, batch_size=batch_size, as_grey=True)\n",
    "validation_data_gen = DataGenerator(dataset_file=config.validation_data_file, batch_size=batch_size, as_grey=True)\n",
    "test_data_gen = DataGenerator(dataset_file=config.test_data_file, batch_size=batch_size, as_grey=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3563 - acc: 0.9587Epoch 00000: val_loss improved from inf to 0.41126, saving model to ./cnn_140_grey_lr_0.001000_nesterov_3_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 360s - loss: 0.3563 - acc: 0.9587 - val_loss: 0.4113 - val_acc: 0.8974\n",
      "Epoch 2/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3563 - acc: 0.9587Epoch 00001: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3562 - acc: 0.9587 - val_loss: 0.4128 - val_acc: 0.8948\n",
      "Epoch 3/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3562 - acc: 0.9587Epoch 00002: val_loss improved from 0.41126 to 0.41078, saving model to ./cnn_140_grey_lr_0.001000_nesterov_3_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 362s - loss: 0.3562 - acc: 0.9587 - val_loss: 0.4108 - val_acc: 0.8970\n",
      "Epoch 4/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3562 - acc: 0.9587Epoch 00003: val_loss improved from 0.41078 to 0.41075, saving model to ./cnn_140_grey_lr_0.001000_nesterov_3_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 362s - loss: 0.3561 - acc: 0.9587 - val_loss: 0.4107 - val_acc: 0.8970\n",
      "Epoch 5/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3561 - acc: 0.9587Epoch 00004: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3561 - acc: 0.9587 - val_loss: 0.4117 - val_acc: 0.8961\n",
      "Epoch 6/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3561 - acc: 0.9587Epoch 00005: val_loss did not improve\n",
      "10496/10496 [==============================] - 360s - loss: 0.3561 - acc: 0.9587 - val_loss: 0.4110 - val_acc: 0.8974\n",
      "Epoch 7/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3561 - acc: 0.9587Epoch 00006: val_loss did not improve\n",
      "10496/10496 [==============================] - 360s - loss: 0.3561 - acc: 0.9587 - val_loss: 0.4130 - val_acc: 0.8952\n",
      "Epoch 8/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3561 - acc: 0.9587Epoch 00007: val_loss improved from 0.41075 to 0.41040, saving model to ./cnn_140_grey_lr_0.001000_nesterov_3_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 361s - loss: 0.3560 - acc: 0.9587 - val_loss: 0.4104 - val_acc: 0.8983\n",
      "Epoch 9/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3560 - acc: 0.9588Epoch 00008: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3560 - acc: 0.9588 - val_loss: 0.4119 - val_acc: 0.8966\n",
      "Epoch 10/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.8263Epoch 00009: val_loss did not improve\n",
      "10496/10496 [==============================] - 360s - loss: nan - acc: 0.8237 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00010: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00011: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00012: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00013: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00014: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00015: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00016: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00017: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00018: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00019: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00020: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00021: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00022: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00023: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00024: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00025: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00026: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00027: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00028: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00029: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.0000e+00Epoch 00030: val_loss did not improve\n",
      "10496/10496 [==============================] - 359s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      " 1088/10496 [==>...........................] - ETA: 313s - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c62c6de5cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer])\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
