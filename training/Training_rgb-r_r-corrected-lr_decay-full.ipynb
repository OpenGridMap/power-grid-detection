{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from utils.training.callbacks import Logger\n",
    "from models.cnn3 import cnn, cnn_regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "decay = 0.0015\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=500\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 3)\n",
    "weights='cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5'\n",
    "\n",
    "name = 'cnn_140_rgb_corrected_full_lr_%f_decay_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, decay, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 18944       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    204864      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    36928       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20777090\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = cnn_regularized(input_shape=input_shape, init='he_normal', l1=l1, l2=l2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True, decay=decay)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "logger = Logger('%s_training_batch.log' % name, append=False)\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=False)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/train_data.csv'\n",
    "validation_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/validation_data.csv'\n",
    "test_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/test_data.csv'\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.4611 - acc: 0.9094Epoch 00000: val_loss improved from inf to 0.08845, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2227s - loss: 2.4611 - acc: 0.9094 - val_loss: 0.0885 - val_acc: 0.9689\n",
      "Epoch 2/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2601 - acc: 0.9729Epoch 00001: val_loss improved from 0.08845 to 0.06791, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 2.2601 - acc: 0.9729 - val_loss: 0.0679 - val_acc: 0.9783\n",
      "Epoch 3/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2423 - acc: 0.9771Epoch 00002: val_loss improved from 0.06791 to 0.06534, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 2.2424 - acc: 0.9771 - val_loss: 0.0653 - val_acc: 0.9789\n",
      "Epoch 4/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2356 - acc: 0.9781Epoch 00003: val_loss improved from 0.06534 to 0.06523, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 2.2357 - acc: 0.9781 - val_loss: 0.0652 - val_acc: 0.9790\n",
      "Epoch 5/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2311 - acc: 0.9783Epoch 00004: val_loss improved from 0.06523 to 0.06302, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2238s - loss: 2.2311 - acc: 0.9783 - val_loss: 0.0630 - val_acc: 0.9797\n",
      "Epoch 6/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2259 - acc: 0.9790Epoch 00005: val_loss improved from 0.06302 to 0.06241, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2237s - loss: 2.2259 - acc: 0.9790 - val_loss: 0.0624 - val_acc: 0.9802\n",
      "Epoch 7/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2225 - acc: 0.9796Epoch 00006: val_loss improved from 0.06241 to 0.06155, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2238s - loss: 2.2226 - acc: 0.9796 - val_loss: 0.0616 - val_acc: 0.9803\n",
      "Epoch 8/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2200 - acc: 0.9795Epoch 00007: val_loss improved from 0.06155 to 0.06102, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 2.2200 - acc: 0.9795 - val_loss: 0.0610 - val_acc: 0.9804\n",
      "Epoch 9/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2177 - acc: 0.9802Epoch 00008: val_loss improved from 0.06102 to 0.06057, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 2.2178 - acc: 0.9802 - val_loss: 0.0606 - val_acc: 0.9803\n",
      "Epoch 10/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2155 - acc: 0.9798Epoch 00009: val_loss improved from 0.06057 to 0.06008, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2227s - loss: 2.2155 - acc: 0.9798 - val_loss: 0.0601 - val_acc: 0.9804\n",
      "Epoch 11/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2135 - acc: 0.9801Epoch 00010: val_loss improved from 0.06008 to 0.05955, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 2.2136 - acc: 0.9801 - val_loss: 0.0596 - val_acc: 0.9809\n",
      "Epoch 12/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2118 - acc: 0.9804Epoch 00011: val_loss improved from 0.05955 to 0.05938, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2231s - loss: 2.2118 - acc: 0.9803 - val_loss: 0.0594 - val_acc: 0.9805\n",
      "Epoch 13/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2108 - acc: 0.9805Epoch 00012: val_loss improved from 0.05938 to 0.05869, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2223s - loss: 2.2108 - acc: 0.9805 - val_loss: 0.0587 - val_acc: 0.9811\n",
      "Epoch 14/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2096 - acc: 0.9803Epoch 00013: val_loss improved from 0.05869 to 0.05836, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 2.2097 - acc: 0.9803 - val_loss: 0.0584 - val_acc: 0.9811\n",
      "Epoch 15/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2079 - acc: 0.9810Epoch 00014: val_loss improved from 0.05836 to 0.05818, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2237s - loss: 2.2080 - acc: 0.9810 - val_loss: 0.0582 - val_acc: 0.9809\n",
      "Epoch 16/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2064 - acc: 0.9805Epoch 00015: val_loss improved from 0.05818 to 0.05781, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 2.2064 - acc: 0.9805 - val_loss: 0.0578 - val_acc: 0.9810\n",
      "Epoch 17/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2051 - acc: 0.9810Epoch 00016: val_loss improved from 0.05781 to 0.05752, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 2.2051 - acc: 0.9810 - val_loss: 0.0575 - val_acc: 0.9812\n",
      "Epoch 18/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2039 - acc: 0.9808Epoch 00017: val_loss did not improve\n",
      "65504/65504 [==============================] - 2231s - loss: 2.2040 - acc: 0.9808 - val_loss: 0.0578 - val_acc: 0.9809\n",
      "Epoch 19/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2030 - acc: 0.9810Epoch 00018: val_loss improved from 0.05752 to 0.05744, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2225s - loss: 2.2031 - acc: 0.9810 - val_loss: 0.0574 - val_acc: 0.9810\n",
      "Epoch 20/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2026 - acc: 0.9807Epoch 00019: val_loss improved from 0.05744 to 0.05656, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2224s - loss: 2.2027 - acc: 0.9806 - val_loss: 0.0566 - val_acc: 0.9815\n",
      "Epoch 21/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2015 - acc: 0.9809Epoch 00020: val_loss improved from 0.05656 to 0.05632, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2238s - loss: 2.2016 - acc: 0.9809 - val_loss: 0.0563 - val_acc: 0.9816\n",
      "Epoch 22/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2007 - acc: 0.9811Epoch 00021: val_loss improved from 0.05632 to 0.05632, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2227s - loss: 2.2007 - acc: 0.9811 - val_loss: 0.0563 - val_acc: 0.9814\n",
      "Epoch 23/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.2001 - acc: 0.9810Epoch 00022: val_loss improved from 0.05632 to 0.05621, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2227s - loss: 2.2002 - acc: 0.9810 - val_loss: 0.0562 - val_acc: 0.9813\n",
      "Epoch 24/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.1990 - acc: 0.9812Epoch 00023: val_loss improved from 0.05621 to 0.05602, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2229s - loss: 2.1990 - acc: 0.9812 - val_loss: 0.0560 - val_acc: 0.9816\n",
      "Epoch 25/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.1981 - acc: 0.9815Epoch 00024: val_loss did not improve\n",
      "65504/65504 [==============================] - 2225s - loss: 2.1982 - acc: 0.9815 - val_loss: 0.0561 - val_acc: 0.9813\n",
      "Epoch 26/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.1974 - acc: 0.9813Epoch 00025: val_loss improved from 0.05602 to 0.05586, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2226s - loss: 2.1975 - acc: 0.9813 - val_loss: 0.0559 - val_acc: 0.9817\n",
      "Epoch 27/500\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 2.1971 - acc: 0.9816Epoch 00026: val_loss improved from 0.05586 to 0.05557, saving model to ./cnn_140_rgb_corrected_full_lr_0.010000_decay_0.001500_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2218s - loss: 2.1972 - acc: 0.9816 - val_loss: 0.0556 - val_acc: 0.9816\n",
      "Epoch 28/500\n",
      " 6848/65504 [==>...........................] - ETA: 1908s - loss: 2.1994 - acc: 0.9806"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-39e8475eb4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_checkpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_model_checkpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               nb_worker=4)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=4, ep)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "done.\n",
      "Test score: 0.055229082056\n",
      "Test accuracy: 0.98305808656\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
