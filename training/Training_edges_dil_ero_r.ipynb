{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.cnn3 import cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_epochs=500\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 1)\n",
    "\n",
    "name = 'cnn_140_edges_dil_ero_lr_%f_nesterov_r' % lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 6400        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    204864      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    36928       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20764546\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "model = cnn(input_shape=input_shape)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=1., clipvalue=0.5, nesterov=True)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "csv_logger = CSVLogger('%s_training.log' % name)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('cnn_140_grey_lr_0.070000_nesterov_training_weights_best.hdf5')\n",
    "# model.load_weights('cnn_140_grey_lr_0.035000_nesterov_1_training_weights_best.hdf5')\n",
    "# model.load_weights('cnn_140_grey_lr_0.010000_nesterov_2_training_weights_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_data_gen = DataGenerator(dataset_file=config.train_data_file, batch_size=batch_size, preprocessing='edges_dil_ero')\n",
    "validation_data_gen = DataGenerator(dataset_file=config.validation_data_file, batch_size=batch_size, preprocessing='edges_dil_ero')\n",
    "test_data_gen = DataGenerator(dataset_file=config.test_data_file, batch_size=batch_size, preprocessing='edges_dil_ero')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6840 - acc: 0.6555Epoch 00000: val_loss improved from inf to 0.67294, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 360s - loss: 0.6840 - acc: 0.6552 - val_loss: 0.6729 - val_acc: 0.6734\n",
      "Epoch 2/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6661 - acc: 0.6650Epoch 00001: val_loss improved from 0.67294 to 0.65770, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 362s - loss: 0.6662 - acc: 0.6647 - val_loss: 0.6577 - val_acc: 0.6717\n",
      "Epoch 3/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6540 - acc: 0.6650Epoch 00002: val_loss improved from 0.65770 to 0.64675, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6541 - acc: 0.6647 - val_loss: 0.6468 - val_acc: 0.6730\n",
      "Epoch 4/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6459 - acc: 0.6650Epoch 00003: val_loss improved from 0.64675 to 0.63947, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6460 - acc: 0.6647 - val_loss: 0.6395 - val_acc: 0.6730\n",
      "Epoch 5/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6402 - acc: 0.6650Epoch 00004: val_loss improved from 0.63947 to 0.63355, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6404 - acc: 0.6647 - val_loss: 0.6336 - val_acc: 0.6743\n",
      "Epoch 6/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6357 - acc: 0.6650Epoch 00005: val_loss improved from 0.63355 to 0.62906, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6358 - acc: 0.6647 - val_loss: 0.6291 - val_acc: 0.6739\n",
      "Epoch 7/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6306 - acc: 0.6650Epoch 00006: val_loss improved from 0.62906 to 0.62409, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6308 - acc: 0.6647 - val_loss: 0.6241 - val_acc: 0.6725\n",
      "Epoch 8/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6231 - acc: 0.6650Epoch 00007: val_loss improved from 0.62409 to 0.61404, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6232 - acc: 0.6647 - val_loss: 0.6140 - val_acc: 0.6743\n",
      "Epoch 9/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.6111 - acc: 0.6650Epoch 00008: val_loss improved from 0.61404 to 0.60114, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.6112 - acc: 0.6647 - val_loss: 0.6011 - val_acc: 0.6734\n",
      "Epoch 10/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.5923 - acc: 0.6651Epoch 00009: val_loss improved from 0.60114 to 0.57806, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.5924 - acc: 0.6648 - val_loss: 0.5781 - val_acc: 0.6783\n",
      "Epoch 11/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.5619 - acc: 0.6954Epoch 00010: val_loss improved from 0.57806 to 0.54342, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.5620 - acc: 0.6954 - val_loss: 0.5434 - val_acc: 0.7548\n",
      "Epoch 12/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.5224 - acc: 0.7617Epoch 00011: val_loss improved from 0.54342 to 0.50627, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.5225 - acc: 0.7615 - val_loss: 0.5063 - val_acc: 0.7835\n",
      "Epoch 13/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4896 - acc: 0.7901Epoch 00012: val_loss improved from 0.50627 to 0.48102, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4897 - acc: 0.7900 - val_loss: 0.4810 - val_acc: 0.7901\n",
      "Epoch 14/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4693 - acc: 0.7947Epoch 00013: val_loss improved from 0.48102 to 0.46643, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4694 - acc: 0.7948 - val_loss: 0.4664 - val_acc: 0.7852\n",
      "Epoch 15/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4568 - acc: 0.7992Epoch 00014: val_loss improved from 0.46643 to 0.45661, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4569 - acc: 0.7992 - val_loss: 0.4566 - val_acc: 0.7861\n",
      "Epoch 16/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4483 - acc: 0.8020Epoch 00015: val_loss improved from 0.45661 to 0.45019, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4485 - acc: 0.8019 - val_loss: 0.4502 - val_acc: 0.7879\n",
      "Epoch 17/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4420 - acc: 0.8038Epoch 00016: val_loss improved from 0.45019 to 0.44329, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4422 - acc: 0.8037 - val_loss: 0.4433 - val_acc: 0.7892\n",
      "Epoch 18/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4368 - acc: 0.8064Epoch 00017: val_loss improved from 0.44329 to 0.43801, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4370 - acc: 0.8063 - val_loss: 0.4380 - val_acc: 0.7918\n",
      "Epoch 19/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4323 - acc: 0.8080Epoch 00018: val_loss improved from 0.43801 to 0.43296, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4325 - acc: 0.8079 - val_loss: 0.4330 - val_acc: 0.7953\n",
      "Epoch 20/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4282 - acc: 0.8109Epoch 00019: val_loss improved from 0.43296 to 0.43045, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4284 - acc: 0.8108 - val_loss: 0.4304 - val_acc: 0.7962\n",
      "Epoch 21/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4245 - acc: 0.8126Epoch 00020: val_loss improved from 0.43045 to 0.42450, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4246 - acc: 0.8125 - val_loss: 0.4245 - val_acc: 0.7993\n",
      "Epoch 22/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4210 - acc: 0.8139Epoch 00021: val_loss improved from 0.42450 to 0.42174, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4212 - acc: 0.8138 - val_loss: 0.4217 - val_acc: 0.8019\n",
      "Epoch 23/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4179 - acc: 0.8153Epoch 00022: val_loss improved from 0.42174 to 0.41702, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4180 - acc: 0.8152 - val_loss: 0.4170 - val_acc: 0.8046\n",
      "Epoch 24/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4147 - acc: 0.8169Epoch 00023: val_loss improved from 0.41702 to 0.41615, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4149 - acc: 0.8168 - val_loss: 0.4162 - val_acc: 0.8033\n",
      "Epoch 25/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4118 - acc: 0.8189Epoch 00024: val_loss improved from 0.41615 to 0.41401, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4120 - acc: 0.8188 - val_loss: 0.4140 - val_acc: 0.8050\n",
      "Epoch 26/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4088 - acc: 0.8206Epoch 00025: val_loss improved from 0.41401 to 0.41210, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4090 - acc: 0.8205 - val_loss: 0.4121 - val_acc: 0.8063\n",
      "Epoch 27/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4061 - acc: 0.8216Epoch 00026: val_loss improved from 0.41210 to 0.41016, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4062 - acc: 0.8215 - val_loss: 0.4102 - val_acc: 0.8072\n",
      "Epoch 28/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4034 - acc: 0.8226Epoch 00027: val_loss improved from 0.41016 to 0.40554, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4036 - acc: 0.8225 - val_loss: 0.4055 - val_acc: 0.8112\n",
      "Epoch 29/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.4008 - acc: 0.8250Epoch 00028: val_loss improved from 0.40554 to 0.40181, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.4010 - acc: 0.8249 - val_loss: 0.4018 - val_acc: 0.8147\n",
      "Epoch 30/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3982 - acc: 0.8272Epoch 00029: val_loss improved from 0.40181 to 0.39971, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3984 - acc: 0.8271 - val_loss: 0.3997 - val_acc: 0.8195\n",
      "Epoch 31/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3958 - acc: 0.8275Epoch 00030: val_loss improved from 0.39971 to 0.39829, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3960 - acc: 0.8274 - val_loss: 0.3983 - val_acc: 0.8182\n",
      "Epoch 32/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3934 - acc: 0.8292Epoch 00031: val_loss improved from 0.39829 to 0.39582, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3936 - acc: 0.8291 - val_loss: 0.3958 - val_acc: 0.8204\n",
      "Epoch 33/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3912 - acc: 0.8308Epoch 00032: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3913 - acc: 0.8307 - val_loss: 0.3963 - val_acc: 0.8209\n",
      "Epoch 34/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3889 - acc: 0.8324Epoch 00033: val_loss improved from 0.39582 to 0.39305, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3891 - acc: 0.8322 - val_loss: 0.3930 - val_acc: 0.8200\n",
      "Epoch 35/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3868 - acc: 0.8340Epoch 00034: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3869 - acc: 0.8338 - val_loss: 0.3945 - val_acc: 0.8217\n",
      "Epoch 36/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3846 - acc: 0.8348Epoch 00035: val_loss improved from 0.39305 to 0.38828, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 364s - loss: 0.3848 - acc: 0.8346 - val_loss: 0.3883 - val_acc: 0.8239\n",
      "Epoch 37/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3825 - acc: 0.8351Epoch 00036: val_loss improved from 0.38828 to 0.38519, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3827 - acc: 0.8349 - val_loss: 0.3852 - val_acc: 0.8266\n",
      "Epoch 38/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3804 - acc: 0.8358Epoch 00037: val_loss improved from 0.38519 to 0.38486, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 364s - loss: 0.3806 - acc: 0.8357 - val_loss: 0.3849 - val_acc: 0.8279\n",
      "Epoch 39/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3783 - acc: 0.8369Epoch 00038: val_loss improved from 0.38486 to 0.38224, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3784 - acc: 0.8367 - val_loss: 0.3822 - val_acc: 0.8310\n",
      "Epoch 40/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3762 - acc: 0.8378Epoch 00039: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3764 - acc: 0.8377 - val_loss: 0.3823 - val_acc: 0.8297\n",
      "Epoch 41/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3742 - acc: 0.8390Epoch 00040: val_loss improved from 0.38224 to 0.37969, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3744 - acc: 0.8389 - val_loss: 0.3797 - val_acc: 0.8323\n",
      "Epoch 42/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3724 - acc: 0.8401Epoch 00041: val_loss improved from 0.37969 to 0.37820, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3725 - acc: 0.8400 - val_loss: 0.3782 - val_acc: 0.8332\n",
      "Epoch 43/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3705 - acc: 0.8408Epoch 00042: val_loss improved from 0.37820 to 0.37767, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3707 - acc: 0.8407 - val_loss: 0.3777 - val_acc: 0.8332\n",
      "Epoch 44/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3688 - acc: 0.8419Epoch 00043: val_loss improved from 0.37767 to 0.37570, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3690 - acc: 0.8419 - val_loss: 0.3757 - val_acc: 0.8319\n",
      "Epoch 45/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3672 - acc: 0.8420Epoch 00044: val_loss improved from 0.37570 to 0.37355, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3673 - acc: 0.8420 - val_loss: 0.3735 - val_acc: 0.8345\n",
      "Epoch 46/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3655 - acc: 0.8426Epoch 00045: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3657 - acc: 0.8426 - val_loss: 0.3741 - val_acc: 0.8341\n",
      "Epoch 47/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3639 - acc: 0.8428Epoch 00046: val_loss improved from 0.37355 to 0.37237, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3641 - acc: 0.8428 - val_loss: 0.3724 - val_acc: 0.8327\n",
      "Epoch 48/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3625 - acc: 0.8431Epoch 00047: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3626 - acc: 0.8431 - val_loss: 0.3726 - val_acc: 0.8327\n",
      "Epoch 49/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3610 - acc: 0.8436Epoch 00048: val_loss improved from 0.37237 to 0.37146, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3612 - acc: 0.8436 - val_loss: 0.3715 - val_acc: 0.8332\n",
      "Epoch 50/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3597 - acc: 0.8446Epoch 00049: val_loss improved from 0.37146 to 0.36975, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 362s - loss: 0.3598 - acc: 0.8446 - val_loss: 0.3697 - val_acc: 0.8358\n",
      "Epoch 51/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3583 - acc: 0.8452Epoch 00050: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3585 - acc: 0.8452 - val_loss: 0.3723 - val_acc: 0.8349\n",
      "Epoch 52/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3570 - acc: 0.8462Epoch 00051: val_loss improved from 0.36975 to 0.36816, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3572 - acc: 0.8462 - val_loss: 0.3682 - val_acc: 0.8367\n",
      "Epoch 53/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3557 - acc: 0.8465Epoch 00052: val_loss improved from 0.36816 to 0.36748, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3559 - acc: 0.8465 - val_loss: 0.3675 - val_acc: 0.8380\n",
      "Epoch 54/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3545 - acc: 0.8471Epoch 00053: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3546 - acc: 0.8471 - val_loss: 0.3685 - val_acc: 0.8349\n",
      "Epoch 55/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3533 - acc: 0.8475Epoch 00054: val_loss improved from 0.36748 to 0.36535, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3534 - acc: 0.8475 - val_loss: 0.3653 - val_acc: 0.8358\n",
      "Epoch 56/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3521 - acc: 0.8473Epoch 00055: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3522 - acc: 0.8473 - val_loss: 0.3674 - val_acc: 0.8332\n",
      "Epoch 57/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3509 - acc: 0.8476Epoch 00056: val_loss improved from 0.36535 to 0.36501, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3511 - acc: 0.8476 - val_loss: 0.3650 - val_acc: 0.8363\n",
      "Epoch 58/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3498 - acc: 0.8481Epoch 00057: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3499 - acc: 0.8481 - val_loss: 0.3655 - val_acc: 0.8363\n",
      "Epoch 59/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3487 - acc: 0.8487Epoch 00058: val_loss improved from 0.36501 to 0.36288, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3489 - acc: 0.8487 - val_loss: 0.3629 - val_acc: 0.8393\n",
      "Epoch 60/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3476 - acc: 0.8492Epoch 00059: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3478 - acc: 0.8492 - val_loss: 0.3642 - val_acc: 0.8371\n",
      "Epoch 61/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3465 - acc: 0.8501Epoch 00060: val_loss improved from 0.36288 to 0.36160, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3467 - acc: 0.8501 - val_loss: 0.3616 - val_acc: 0.8396\n",
      "Epoch 62/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3454 - acc: 0.8512Epoch 00061: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3456 - acc: 0.8512 - val_loss: 0.3636 - val_acc: 0.8387\n",
      "Epoch 63/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3444 - acc: 0.8521Epoch 00062: val_loss improved from 0.36160 to 0.36131, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3445 - acc: 0.8520 - val_loss: 0.3613 - val_acc: 0.8418\n",
      "Epoch 64/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3433 - acc: 0.8521Epoch 00063: val_loss improved from 0.36131 to 0.35885, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3434 - acc: 0.8520 - val_loss: 0.3588 - val_acc: 0.8426\n",
      "Epoch 65/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3423 - acc: 0.8532Epoch 00064: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3424 - acc: 0.8532 - val_loss: 0.3593 - val_acc: 0.8413\n",
      "Epoch 66/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3412 - acc: 0.8533Epoch 00065: val_loss did not improve\n",
      "10496/10496 [==============================] - 361s - loss: 0.3413 - acc: 0.8533 - val_loss: 0.3592 - val_acc: 0.8426\n",
      "Epoch 67/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3401 - acc: 0.8537Epoch 00066: val_loss improved from 0.35885 to 0.35839, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3403 - acc: 0.8537 - val_loss: 0.3584 - val_acc: 0.8413\n",
      "Epoch 68/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3391 - acc: 0.8541Epoch 00067: val_loss improved from 0.35839 to 0.35721, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 364s - loss: 0.3393 - acc: 0.8540 - val_loss: 0.3572 - val_acc: 0.8422\n",
      "Epoch 69/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3382 - acc: 0.8546Epoch 00068: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3383 - acc: 0.8546 - val_loss: 0.3609 - val_acc: 0.8409\n",
      "Epoch 70/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3372 - acc: 0.8543Epoch 00069: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3374 - acc: 0.8543 - val_loss: 0.3580 - val_acc: 0.8418\n",
      "Epoch 71/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3362 - acc: 0.8554Epoch 00070: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3364 - acc: 0.8554 - val_loss: 0.3588 - val_acc: 0.8418\n",
      "Epoch 72/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3353 - acc: 0.8560Epoch 00071: val_loss did not improve\n",
      "10496/10496 [==============================] - 362s - loss: 0.3354 - acc: 0.8560 - val_loss: 0.3584 - val_acc: 0.8422\n",
      "Epoch 73/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3343 - acc: 0.8568Epoch 00072: val_loss improved from 0.35721 to 0.35642, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3345 - acc: 0.8568 - val_loss: 0.3564 - val_acc: 0.8435\n",
      "Epoch 74/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 0.3334 - acc: 0.8576Epoch 00073: val_loss improved from 0.35642 to 0.35514, saving model to ./cnn_140_edges_dil_ero_lr_0.001000_nesterov_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 363s - loss: 0.3335 - acc: 0.8576 - val_loss: 0.3551 - val_acc: 0.8438\n",
      "Epoch 75/500\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: nan - acc: 0.3957Epoch 00074: val_loss did not improve\n",
      "10496/10496 [==============================] - 360s - loss: nan - acc: 0.3945 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      " 2080/10496 [====>.........................] - ETA: 281s - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c62c6de5cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer])\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Test score: nan\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "### print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
