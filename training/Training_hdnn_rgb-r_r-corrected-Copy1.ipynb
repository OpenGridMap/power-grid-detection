{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp9x13bn/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp9x13bn/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5110)\n",
      "C:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.hdnn import hdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=100\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 3)\n",
    "\n",
    "name = 'hdnn_relu_140_rgb_corrected_lr_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "Compiling conv2d layer: stage 1 block 1...\n",
      "Compiling conv2d layer: stage 2 block 1...\n",
      "Compiling conv2d layer: stage 3 block 1...\n",
      "Creating hybrid block with 3 conv2d blocks: stage 4\n",
      "Compiling conv2d layer: stage 4 block 1...\n",
      "Compiling conv2d layer: stage 4 block 2...\n",
      "Compiling conv2d layer: stage 4 block 3...\n",
      "Merging hybrid blocks : stage 4\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "C1_1 (Convolution2D)             (None, 134, 134, 84)  12432       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 134, 134, 84)  0           C1_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M1_1 (MaxPooling2D)              (None, 67, 67, 84)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C2_1 (Convolution2D)             (None, 64, 64, 84)    112980      M1_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 64, 64, 84)    0           C2_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M2_1 (MaxPooling2D)              (None, 32, 32, 84)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C3_1 (Convolution2D)             (None, 29, 29, 54)    72630       M2_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 29, 29, 54)    0           C3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M3_1 (MaxPooling2D)              (None, 14, 14, 54)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "C4_1 (Convolution2D)             (None, 6, 6, 54)      46710       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "C4_2 (Convolution2D)             (None, 6, 6, 20)      17300       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "C4_3 (Convolution2D)             (None, 5, 5, 10)      19450       M3_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 6, 6, 54)      0           C4_1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 6, 6, 20)      0           C4_2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 5, 5, 10)      0           C4_3[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "M4_1 (MaxPooling2D)              (None, 3, 3, 54)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "M4_2 (MaxPooling2D)              (None, 3, 3, 20)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "M4_3 (MaxPooling2D)              (None, 3, 3, 10)      0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 3, 3, 84)      0           M4_1[0][0]                       \n",
      "                                                                   M4_2[0][0]                       \n",
      "                                                                   M4_3[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 756)           0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 300)           227100      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             602         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 2)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 509,204\n",
      "Trainable params: 509,204\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = hdnn(input_shape=input_shape, activation_fn='relu', init='he_normal', l1=l1, l2=l2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=True)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = config.corrected_train_data_file\n",
    "validation_set_file = config.corrected_validation_data_file\n",
    "test_set_file = config.corrected_test_data_file\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpsik4vu/5d8a7bab200dc8090d4573cde3b5cd46.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpsik4vu/5d8a7bab200dc8090d4573cde3b5cd46.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpykv5_x/231730f5ff4cdd4403902aa79e1ec083.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpykv5_x/231730f5ff4cdd4403902aa79e1ec083.exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.6565Epoch 00000: val_loss improved from inf to 0.66901, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.6935 - acc: 0.6562 - val_loss: 0.6690 - val_acc: 0.6734\n",
      "Epoch 2/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.6652Epoch 00001: val_loss improved from 0.66901 to 0.63684, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.6592 - acc: 0.6649 - val_loss: 0.6368 - val_acc: 0.6734\n",
      "Epoch 3/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.7486Epoch 00002: val_loss improved from 0.63684 to 0.35191, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.5513 - acc: 0.7490 - val_loss: 0.3519 - val_acc: 0.8754\n",
      "Epoch 4/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.8901Epoch 00003: val_loss improved from 0.35191 to 0.24053, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.3485 - acc: 0.8902 - val_loss: 0.2405 - val_acc: 0.9327\n",
      "Epoch 5/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9437Epoch 00004: val_loss improved from 0.24053 to 0.15271, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.2168 - acc: 0.9439 - val_loss: 0.1527 - val_acc: 0.9679\n",
      "Epoch 6/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9593Epoch 00005: val_loss improved from 0.15271 to 0.13462, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1661 - acc: 0.9594 - val_loss: 0.1346 - val_acc: 0.9696\n",
      "Epoch 7/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9628Epoch 00006: val_loss improved from 0.13462 to 0.12970, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1547 - acc: 0.9629 - val_loss: 0.1297 - val_acc: 0.9732\n",
      "Epoch 8/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9644Epoch 00007: val_loss improved from 0.12970 to 0.12698, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1491 - acc: 0.9645 - val_loss: 0.1270 - val_acc: 0.9727\n",
      "Epoch 9/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9657Epoch 00008: val_loss improved from 0.12698 to 0.12533, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 119s - loss: 0.1451 - acc: 0.9658 - val_loss: 0.1253 - val_acc: 0.9732\n",
      "Epoch 10/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9660Epoch 00009: val_loss improved from 0.12533 to 0.12277, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 123s - loss: 0.1415 - acc: 0.9661 - val_loss: 0.1228 - val_acc: 0.9749\n",
      "Epoch 11/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9672Epoch 00010: val_loss improved from 0.12277 to 0.12116, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 120s - loss: 0.1382 - acc: 0.9673 - val_loss: 0.1212 - val_acc: 0.9758\n",
      "Epoch 12/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9675Epoch 00011: val_loss did not improve\n",
      "10496/10496 [==============================] - 119s - loss: 0.1351 - acc: 0.9676 - val_loss: 0.1251 - val_acc: 0.9745\n",
      "Epoch 13/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9688Epoch 00012: val_loss improved from 0.12116 to 0.11663, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.1320 - acc: 0.9688 - val_loss: 0.1166 - val_acc: 0.9758\n",
      "Epoch 14/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9694Epoch 00013: val_loss improved from 0.11663 to 0.11427, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.1290 - acc: 0.9695 - val_loss: 0.1143 - val_acc: 0.9758\n",
      "Epoch 15/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9700Epoch 00014: val_loss improved from 0.11427 to 0.11228, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1260 - acc: 0.9701 - val_loss: 0.1123 - val_acc: 0.9762\n",
      "Epoch 16/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9704Epoch 00015: val_loss improved from 0.11228 to 0.10981, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.1232 - acc: 0.9705 - val_loss: 0.1098 - val_acc: 0.9771\n",
      "Epoch 17/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9708Epoch 00016: val_loss improved from 0.10981 to 0.10761, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1203 - acc: 0.9708 - val_loss: 0.1076 - val_acc: 0.9762\n",
      "Epoch 18/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9716Epoch 00017: val_loss improved from 0.10761 to 0.10564, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1176 - acc: 0.9717 - val_loss: 0.1056 - val_acc: 0.9767\n",
      "Epoch 19/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9727Epoch 00018: val_loss improved from 0.10564 to 0.10319, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.1148 - acc: 0.9728 - val_loss: 0.1032 - val_acc: 0.9780\n",
      "Epoch 20/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9738Epoch 00019: val_loss improved from 0.10319 to 0.10254, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1120 - acc: 0.9739 - val_loss: 0.1025 - val_acc: 0.9771\n",
      "Epoch 21/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9749Epoch 00020: val_loss improved from 0.10254 to 0.09983, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1097 - acc: 0.9749 - val_loss: 0.0998 - val_acc: 0.9798\n",
      "Epoch 22/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9752Epoch 00021: val_loss improved from 0.09983 to 0.09819, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1076 - acc: 0.9753 - val_loss: 0.0982 - val_acc: 0.9802\n",
      "Epoch 23/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9752Epoch 00022: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.1058 - acc: 0.9753 - val_loss: 0.0985 - val_acc: 0.9802\n",
      "Epoch 24/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9756Epoch 00023: val_loss improved from 0.09819 to 0.09523, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1039 - acc: 0.9757 - val_loss: 0.0952 - val_acc: 0.9802\n",
      "Epoch 25/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9759Epoch 00024: val_loss improved from 0.09523 to 0.09374, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1024 - acc: 0.9760 - val_loss: 0.0937 - val_acc: 0.9802\n",
      "Epoch 26/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9768Epoch 00025: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.1013 - acc: 0.9768 - val_loss: 0.0943 - val_acc: 0.9802\n",
      "Epoch 27/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9774Epoch 00026: val_loss improved from 0.09374 to 0.09238, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.1000 - acc: 0.9775 - val_loss: 0.0924 - val_acc: 0.9811\n",
      "Epoch 28/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9774Epoch 00027: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0990 - acc: 0.9775 - val_loss: 0.0935 - val_acc: 0.9806\n",
      "Epoch 29/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9774Epoch 00028: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0979 - acc: 0.9774 - val_loss: 0.0949 - val_acc: 0.9811\n",
      "Epoch 30/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9778Epoch 00029: val_loss improved from 0.09238 to 0.09054, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0969 - acc: 0.9779 - val_loss: 0.0905 - val_acc: 0.9820\n",
      "Epoch 31/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9780Epoch 00030: val_loss improved from 0.09054 to 0.08980, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0959 - acc: 0.9781 - val_loss: 0.0898 - val_acc: 0.9824\n",
      "Epoch 32/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9781Epoch 00031: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0953 - acc: 0.9782 - val_loss: 0.0906 - val_acc: 0.9824\n",
      "Epoch 33/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9784Epoch 00032: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0946 - acc: 0.9785 - val_loss: 0.0915 - val_acc: 0.9820\n",
      "Epoch 34/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9785Epoch 00033: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0938 - acc: 0.9786 - val_loss: 0.0900 - val_acc: 0.9824\n",
      "Epoch 35/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9785Epoch 00034: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0931 - acc: 0.9786 - val_loss: 0.0919 - val_acc: 0.9820\n",
      "Epoch 36/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9784Epoch 00035: val_loss improved from 0.08980 to 0.08764, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0924 - acc: 0.9785 - val_loss: 0.0876 - val_acc: 0.9828\n",
      "Epoch 37/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9790Epoch 00036: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0917 - acc: 0.9790 - val_loss: 0.0877 - val_acc: 0.9824\n",
      "Epoch 38/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9793Epoch 00037: val_loss improved from 0.08764 to 0.08685, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0910 - acc: 0.9793 - val_loss: 0.0869 - val_acc: 0.9828\n",
      "Epoch 39/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9795Epoch 00038: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0903 - acc: 0.9796 - val_loss: 0.0891 - val_acc: 0.9820\n",
      "Epoch 40/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9800Epoch 00039: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0896 - acc: 0.9801 - val_loss: 0.0890 - val_acc: 0.9820\n",
      "Epoch 41/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9803Epoch 00040: val_loss improved from 0.08685 to 0.08595, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0889 - acc: 0.9804 - val_loss: 0.0859 - val_acc: 0.9817\n",
      "Epoch 42/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9802Epoch 00041: val_loss improved from 0.08595 to 0.08516, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0882 - acc: 0.9803 - val_loss: 0.0852 - val_acc: 0.9822\n",
      "Epoch 43/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9804Epoch 00042: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0876 - acc: 0.9805 - val_loss: 0.0861 - val_acc: 0.9804\n",
      "Epoch 44/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9807Epoch 00043: val_loss improved from 0.08516 to 0.08464, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0870 - acc: 0.9808 - val_loss: 0.0846 - val_acc: 0.9817\n",
      "Epoch 45/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9809Epoch 00044: val_loss improved from 0.08464 to 0.08406, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0863 - acc: 0.9809 - val_loss: 0.0841 - val_acc: 0.9813\n",
      "Epoch 46/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9809Epoch 00045: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0857 - acc: 0.9810 - val_loss: 0.0843 - val_acc: 0.9804\n",
      "Epoch 47/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9813Epoch 00046: val_loss improved from 0.08406 to 0.08367, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0850 - acc: 0.9813 - val_loss: 0.0837 - val_acc: 0.9813\n",
      "Epoch 48/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9813Epoch 00047: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0845 - acc: 0.9814 - val_loss: 0.0845 - val_acc: 0.9800\n",
      "Epoch 49/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9816Epoch 00048: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0840 - acc: 0.9817 - val_loss: 0.0842 - val_acc: 0.9802\n",
      "Epoch 50/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9815Epoch 00049: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0834 - acc: 0.9816 - val_loss: 0.0859 - val_acc: 0.9804\n",
      "Epoch 51/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9815Epoch 00050: val_loss improved from 0.08367 to 0.08223, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0828 - acc: 0.9816 - val_loss: 0.0822 - val_acc: 0.9809\n",
      "Epoch 52/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9813Epoch 00051: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0825 - acc: 0.9814 - val_loss: 0.0823 - val_acc: 0.9813\n",
      "Epoch 53/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9813Epoch 00052: val_loss improved from 0.08223 to 0.08196, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0819 - acc: 0.9814 - val_loss: 0.0820 - val_acc: 0.9813\n",
      "Epoch 54/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9815Epoch 00053: val_loss improved from 0.08196 to 0.08191, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0814 - acc: 0.9816 - val_loss: 0.0819 - val_acc: 0.9809\n",
      "Epoch 55/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9817Epoch 00054: val_loss improved from 0.08191 to 0.08138, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0809 - acc: 0.9818 - val_loss: 0.0814 - val_acc: 0.9811\n",
      "Epoch 56/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9821Epoch 00055: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0804 - acc: 0.9821 - val_loss: 0.0829 - val_acc: 0.9802\n",
      "Epoch 57/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9822Epoch 00056: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0800 - acc: 0.9822 - val_loss: 0.0843 - val_acc: 0.9806\n",
      "Epoch 58/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9827Epoch 00057: val_loss improved from 0.08138 to 0.08062, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0796 - acc: 0.9827 - val_loss: 0.0806 - val_acc: 0.9811\n",
      "Epoch 59/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9828Epoch 00058: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0792 - acc: 0.9829 - val_loss: 0.0809 - val_acc: 0.9806\n",
      "Epoch 60/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9829Epoch 00059: val_loss did not improve\n",
      "10496/10496 [==============================] - 119s - loss: 0.0787 - acc: 0.9830 - val_loss: 0.0807 - val_acc: 0.9811\n",
      "Epoch 61/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9835Epoch 00060: val_loss improved from 0.08062 to 0.08045, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0782 - acc: 0.9836 - val_loss: 0.0804 - val_acc: 0.9806\n",
      "Epoch 62/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9837Epoch 00061: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0779 - acc: 0.9837 - val_loss: 0.0817 - val_acc: 0.9798\n",
      "Epoch 63/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9844Epoch 00062: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0773 - acc: 0.9845 - val_loss: 0.0813 - val_acc: 0.9798\n",
      "Epoch 64/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9841Epoch 00063: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0770 - acc: 0.9842 - val_loss: 0.0810 - val_acc: 0.9798\n",
      "Epoch 65/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9842Epoch 00064: val_loss improved from 0.08045 to 0.07971, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0766 - acc: 0.9843 - val_loss: 0.0797 - val_acc: 0.9806\n",
      "Epoch 66/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9842Epoch 00065: val_loss improved from 0.07971 to 0.07958, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0763 - acc: 0.9843 - val_loss: 0.0796 - val_acc: 0.9811\n",
      "Epoch 67/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9842Epoch 00066: val_loss improved from 0.07958 to 0.07924, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0759 - acc: 0.9843 - val_loss: 0.0792 - val_acc: 0.9806\n",
      "Epoch 68/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9847Epoch 00067: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0754 - acc: 0.9848 - val_loss: 0.0796 - val_acc: 0.9811\n",
      "Epoch 69/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9849Epoch 00068: val_loss improved from 0.07924 to 0.07890, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0751 - acc: 0.9849 - val_loss: 0.0789 - val_acc: 0.9811\n",
      "Epoch 70/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9849Epoch 00069: val_loss improved from 0.07890 to 0.07855, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0747 - acc: 0.9849 - val_loss: 0.0786 - val_acc: 0.9806\n",
      "Epoch 71/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9850Epoch 00070: val_loss improved from 0.07855 to 0.07853, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0744 - acc: 0.9850 - val_loss: 0.0785 - val_acc: 0.9811\n",
      "Epoch 72/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9849Epoch 00071: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0740 - acc: 0.9849 - val_loss: 0.0788 - val_acc: 0.9811\n",
      "Epoch 73/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9853Epoch 00072: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0737 - acc: 0.9854 - val_loss: 0.0787 - val_acc: 0.9811\n",
      "Epoch 74/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9854Epoch 00073: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0733 - acc: 0.9854 - val_loss: 0.0786 - val_acc: 0.9811\n",
      "Epoch 75/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9854Epoch 00074: val_loss improved from 0.07853 to 0.07839, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0729 - acc: 0.9855 - val_loss: 0.0784 - val_acc: 0.9811\n",
      "Epoch 76/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9855Epoch 00075: val_loss improved from 0.07839 to 0.07838, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0726 - acc: 0.9856 - val_loss: 0.0784 - val_acc: 0.9809\n",
      "Epoch 77/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9855Epoch 00076: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0722 - acc: 0.9856 - val_loss: 0.0793 - val_acc: 0.9802\n",
      "Epoch 78/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9855Epoch 00077: val_loss improved from 0.07838 to 0.07749, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0719 - acc: 0.9856 - val_loss: 0.0775 - val_acc: 0.9811\n",
      "Epoch 79/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9855Epoch 00078: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0716 - acc: 0.9856 - val_loss: 0.0778 - val_acc: 0.9815\n",
      "Epoch 80/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9860Epoch 00079: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0712 - acc: 0.9861 - val_loss: 0.0777 - val_acc: 0.9806\n",
      "Epoch 81/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9862Epoch 00080: val_loss improved from 0.07749 to 0.07722, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0709 - acc: 0.9863 - val_loss: 0.0772 - val_acc: 0.9811\n",
      "Epoch 82/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9862Epoch 00081: val_loss improved from 0.07722 to 0.07685, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0706 - acc: 0.9863 - val_loss: 0.0769 - val_acc: 0.9811\n",
      "Epoch 83/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9864Epoch 00082: val_loss improved from 0.07685 to 0.07680, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0703 - acc: 0.9864 - val_loss: 0.0768 - val_acc: 0.9811\n",
      "Epoch 84/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9865Epoch 00083: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0700 - acc: 0.9866 - val_loss: 0.0786 - val_acc: 0.9802\n",
      "Epoch 85/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9865Epoch 00084: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0696 - acc: 0.9866 - val_loss: 0.0781 - val_acc: 0.9802\n",
      "Epoch 86/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9868Epoch 00085: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0693 - acc: 0.9868 - val_loss: 0.0770 - val_acc: 0.9811\n",
      "Epoch 87/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9871Epoch 00086: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0690 - acc: 0.9871 - val_loss: 0.0779 - val_acc: 0.9806\n",
      "Epoch 88/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9869Epoch 00087: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0687 - acc: 0.9869 - val_loss: 0.0780 - val_acc: 0.9806\n",
      "Epoch 89/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9870Epoch 00088: val_loss improved from 0.07680 to 0.07677, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0684 - acc: 0.9870 - val_loss: 0.0768 - val_acc: 0.9815\n",
      "Epoch 90/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9871Epoch 00089: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0682 - acc: 0.9871 - val_loss: 0.0779 - val_acc: 0.9806\n",
      "Epoch 91/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9869Epoch 00090: val_loss improved from 0.07677 to 0.07653, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 119s - loss: 0.0678 - acc: 0.9869 - val_loss: 0.0765 - val_acc: 0.9815\n",
      "Epoch 92/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9872Epoch 00091: val_loss improved from 0.07653 to 0.07652, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 119s - loss: 0.0676 - acc: 0.9872 - val_loss: 0.0765 - val_acc: 0.9815\n",
      "Epoch 93/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9871Epoch 00092: val_loss did not improve\n",
      "10496/10496 [==============================] - 118s - loss: 0.0674 - acc: 0.9872 - val_loss: 0.0793 - val_acc: 0.9809\n",
      "Epoch 94/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9875Epoch 00093: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0671 - acc: 0.9875 - val_loss: 0.0786 - val_acc: 0.9813\n",
      "Epoch 95/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9870Epoch 00094: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0669 - acc: 0.9870 - val_loss: 0.0766 - val_acc: 0.9817\n",
      "Epoch 96/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9871Epoch 00095: val_loss improved from 0.07652 to 0.07628, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 118s - loss: 0.0665 - acc: 0.9871 - val_loss: 0.0763 - val_acc: 0.9817\n",
      "Epoch 97/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9871Epoch 00096: val_loss did not improve\n",
      "10496/10496 [==============================] - 117s - loss: 0.0663 - acc: 0.9871 - val_loss: 0.0765 - val_acc: 0.9822\n",
      "Epoch 98/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9874Epoch 00097: val_loss improved from 0.07628 to 0.07602, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0660 - acc: 0.9875 - val_loss: 0.0760 - val_acc: 0.9822\n",
      "Epoch 99/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9874Epoch 00098: val_loss improved from 0.07602 to 0.07478, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0656 - acc: 0.9875 - val_loss: 0.0748 - val_acc: 0.9817\n",
      "Epoch 100/100\n",
      "10464/10496 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9877Epoch 00099: val_loss improved from 0.07478 to 0.07471, saving model to ./hdnn_relu_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 117s - loss: 0.0656 - acc: 0.9878 - val_loss: 0.0747 - val_acc: 0.9813\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=2)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "done.\n",
      "Test score: 0.0836680067152\n",
      "Test accuracy: 0.983934859155\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
