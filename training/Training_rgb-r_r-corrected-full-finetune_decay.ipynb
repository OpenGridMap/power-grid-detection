{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.cnn3 import cnn, cnn_regularized\n",
    "from utils.training.callbacks import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.05\n",
    "decay = 0.003\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=100\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 3)\n",
    "weights='cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5'\n",
    "\n",
    "name = 'cnn_140_rgb_corrected_full_finetune_decay_lr_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 18944       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    204864      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    36928       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20777090\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = cnn_regularized(input_shape=input_shape, init='he_normal', l1=l1, l2=l2, weights=weights)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True, decay=decay)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "logger = Logger('%s_training_batch.log' % name, append=True)\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=True)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/train_data.csv'\n",
    "validation_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/validation_data.csv'\n",
    "test_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/test_data.csv'\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.9374 - acc: 0.9824Epoch 00000: val_loss improved from inf to 0.03345, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2222s - loss: 1.9374 - acc: 0.9824 - val_loss: 0.0334 - val_acc: 0.9886\n",
      "Epoch 2/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8868 - acc: 0.9875Epoch 00001: val_loss improved from 0.03345 to 0.02942, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 1.8869 - acc: 0.9875 - val_loss: 0.0294 - val_acc: 0.9897\n",
      "Epoch 3/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8687 - acc: 0.9890Epoch 00002: val_loss improved from 0.02942 to 0.02812, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2230s - loss: 1.8687 - acc: 0.9889 - val_loss: 0.0281 - val_acc: 0.9899\n",
      "Epoch 4/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8567 - acc: 0.9896Epoch 00003: val_loss improved from 0.02812 to 0.02735, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2231s - loss: 1.8568 - acc: 0.9895 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 5/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8483 - acc: 0.9900Epoch 00004: val_loss improved from 0.02735 to 0.02693, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2231s - loss: 1.8484 - acc: 0.9900 - val_loss: 0.0269 - val_acc: 0.9907\n",
      "Epoch 6/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8415 - acc: 0.9902Epoch 00005: val_loss improved from 0.02693 to 0.02640, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2228s - loss: 1.8415 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9910\n",
      "Epoch 7/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8362 - acc: 0.9906Epoch 00006: val_loss improved from 0.02640 to 0.02570, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2224s - loss: 1.8362 - acc: 0.9906 - val_loss: 0.0257 - val_acc: 0.9912\n",
      "Epoch 8/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8316 - acc: 0.9905Epoch 00007: val_loss improved from 0.02570 to 0.02556, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2225s - loss: 1.8317 - acc: 0.9905 - val_loss: 0.0256 - val_acc: 0.9912\n",
      "Epoch 9/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8274 - acc: 0.9907Epoch 00008: val_loss improved from 0.02556 to 0.02498, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2226s - loss: 1.8274 - acc: 0.9907 - val_loss: 0.0250 - val_acc: 0.9914\n",
      "Epoch 10/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8241 - acc: 0.9908Epoch 00009: val_loss improved from 0.02498 to 0.02489, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2215s - loss: 1.8241 - acc: 0.9908 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "Epoch 11/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8203 - acc: 0.9908Epoch 00010: val_loss improved from 0.02489 to 0.02465, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2218s - loss: 1.8204 - acc: 0.9908 - val_loss: 0.0247 - val_acc: 0.9915\n",
      "Epoch 12/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8176 - acc: 0.9912Epoch 00011: val_loss did not improve\n",
      "65504/65504 [==============================] - 2223s - loss: 1.8176 - acc: 0.9912 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 13/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8149 - acc: 0.9912Epoch 00012: val_loss improved from 0.02465 to 0.02453, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2215s - loss: 1.8149 - acc: 0.9912 - val_loss: 0.0245 - val_acc: 0.9916\n",
      "Epoch 14/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8126 - acc: 0.9913Epoch 00013: val_loss improved from 0.02453 to 0.02424, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2220s - loss: 1.8127 - acc: 0.9913 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 15/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8100 - acc: 0.9912Epoch 00014: val_loss improved from 0.02424 to 0.02396, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2232s - loss: 1.8100 - acc: 0.9912 - val_loss: 0.0240 - val_acc: 0.9919\n",
      "Epoch 16/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8078 - acc: 0.9912Epoch 00015: val_loss did not improve\n",
      "65504/65504 [==============================] - 2217s - loss: 1.8079 - acc: 0.9912 - val_loss: 0.0241 - val_acc: 0.9918\n",
      "Epoch 17/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8060 - acc: 0.9914Epoch 00016: val_loss improved from 0.02396 to 0.02381, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2224s - loss: 1.8060 - acc: 0.9914 - val_loss: 0.0238 - val_acc: 0.9920\n",
      "Epoch 18/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8040 - acc: 0.9915Epoch 00017: val_loss improved from 0.02381 to 0.02366, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2227s - loss: 1.8040 - acc: 0.9915 - val_loss: 0.0237 - val_acc: 0.9921\n",
      "Epoch 19/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8021 - acc: 0.9917Epoch 00018: val_loss did not improve\n",
      "65504/65504 [==============================] - 2226s - loss: 1.8021 - acc: 0.9917 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "Epoch 20/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.8004 - acc: 0.9917Epoch 00019: val_loss improved from 0.02366 to 0.02352, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2229s - loss: 1.8005 - acc: 0.9917 - val_loss: 0.0235 - val_acc: 0.9921\n",
      "Epoch 21/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7989 - acc: 0.9917Epoch 00020: val_loss improved from 0.02352 to 0.02348, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2229s - loss: 1.7989 - acc: 0.9917 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "Epoch 22/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7973 - acc: 0.9920Epoch 00021: val_loss improved from 0.02348 to 0.02336, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2232s - loss: 1.7973 - acc: 0.9920 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "Epoch 23/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7960 - acc: 0.9920Epoch 00022: val_loss did not improve\n",
      "65504/65504 [==============================] - 2228s - loss: 1.7961 - acc: 0.9920 - val_loss: 0.0234 - val_acc: 0.9921\n",
      "Epoch 24/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7949 - acc: 0.9917Epoch 00023: val_loss improved from 0.02336 to 0.02317, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2234s - loss: 1.7949 - acc: 0.9917 - val_loss: 0.0232 - val_acc: 0.9924\n",
      "Epoch 25/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7933 - acc: 0.9917Epoch 00024: val_loss improved from 0.02317 to 0.02317, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7934 - acc: 0.9916 - val_loss: 0.0232 - val_acc: 0.9922\n",
      "Epoch 26/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7923 - acc: 0.9921Epoch 00025: val_loss improved from 0.02317 to 0.02306, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2240s - loss: 1.7923 - acc: 0.9921 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 27/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7909 - acc: 0.9920Epoch 00026: val_loss improved from 0.02306 to 0.02298, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2237s - loss: 1.7910 - acc: 0.9920 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "Epoch 28/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7899 - acc: 0.9921Epoch 00027: val_loss improved from 0.02298 to 0.02290, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2240s - loss: 1.7899 - acc: 0.9921 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 29/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7884 - acc: 0.9923Epoch 00028: val_loss did not improve\n",
      "65504/65504 [==============================] - 2238s - loss: 1.7884 - acc: 0.9922 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 30/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7875 - acc: 0.9920Epoch 00029: val_loss improved from 0.02290 to 0.02286, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 1.7875 - acc: 0.9920 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 31/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7866 - acc: 0.9923Epoch 00030: val_loss improved from 0.02286 to 0.02281, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2238s - loss: 1.7867 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9922\n",
      "Epoch 32/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7856 - acc: 0.9920Epoch 00031: val_loss improved from 0.02281 to 0.02280, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 1.7856 - acc: 0.9920 - val_loss: 0.0228 - val_acc: 0.9925\n",
      "Epoch 33/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7848 - acc: 0.9921Epoch 00032: val_loss improved from 0.02280 to 0.02279, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7848 - acc: 0.9921 - val_loss: 0.0228 - val_acc: 0.9924\n",
      "Epoch 34/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7837 - acc: 0.9923Epoch 00033: val_loss improved from 0.02279 to 0.02277, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2239s - loss: 1.7837 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 35/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7827 - acc: 0.9921Epoch 00034: val_loss improved from 0.02277 to 0.02263, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2236s - loss: 1.7827 - acc: 0.9921 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 36/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7822 - acc: 0.9923Epoch 00035: val_loss did not improve\n",
      "65504/65504 [==============================] - 2237s - loss: 1.7822 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9925\n",
      "Epoch 37/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7811 - acc: 0.9922Epoch 00036: val_loss improved from 0.02263 to 0.02259, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2238s - loss: 1.7812 - acc: 0.9922 - val_loss: 0.0226 - val_acc: 0.9927\n",
      "Epoch 38/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7803 - acc: 0.9924Epoch 00037: val_loss did not improve\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7803 - acc: 0.9924 - val_loss: 0.0227 - val_acc: 0.9925\n",
      "Epoch 39/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7793 - acc: 0.9925Epoch 00038: val_loss improved from 0.02259 to 0.02251, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2230s - loss: 1.7794 - acc: 0.9925 - val_loss: 0.0225 - val_acc: 0.9926\n",
      "Epoch 40/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7786 - acc: 0.9924Epoch 00039: val_loss did not improve\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7787 - acc: 0.9924 - val_loss: 0.0225 - val_acc: 0.9925\n",
      "Epoch 41/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7782 - acc: 0.9924Epoch 00040: val_loss improved from 0.02251 to 0.02247, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7782 - acc: 0.9924 - val_loss: 0.0225 - val_acc: 0.9925\n",
      "Epoch 42/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7769 - acc: 0.9927Epoch 00041: val_loss did not improve\n",
      "65504/65504 [==============================] - 2232s - loss: 1.7769 - acc: 0.9926 - val_loss: 0.0225 - val_acc: 0.9927\n",
      "Epoch 43/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7766 - acc: 0.9924Epoch 00042: val_loss improved from 0.02247 to 0.02240, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2235s - loss: 1.7767 - acc: 0.9924 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 44/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7758 - acc: 0.9924Epoch 00043: val_loss did not improve\n",
      "65504/65504 [==============================] - 2237s - loss: 1.7759 - acc: 0.9924 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 45/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7755 - acc: 0.9922Epoch 00044: val_loss improved from 0.02240 to 0.02233, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2229s - loss: 1.7755 - acc: 0.9922 - val_loss: 0.0223 - val_acc: 0.9927\n",
      "Epoch 46/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7744 - acc: 0.9926Epoch 00045: val_loss improved from 0.02233 to 0.02232, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2233s - loss: 1.7744 - acc: 0.9926 - val_loss: 0.0223 - val_acc: 0.9929\n",
      "Epoch 47/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7735 - acc: 0.9924Epoch 00046: val_loss did not improve\n",
      "65504/65504 [==============================] - 2231s - loss: 1.7735 - acc: 0.9924 - val_loss: 0.0224 - val_acc: 0.9926\n",
      "Epoch 48/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7729 - acc: 0.9926Epoch 00047: val_loss improved from 0.02232 to 0.02226, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2224s - loss: 1.7729 - acc: 0.9926 - val_loss: 0.0223 - val_acc: 0.9927\n",
      "Epoch 49/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7724 - acc: 0.9925Epoch 00048: val_loss did not improve\n",
      "65504/65504 [==============================] - 2221s - loss: 1.7724 - acc: 0.9925 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 50/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7720 - acc: 0.9924Epoch 00049: val_loss did not improve\n",
      "65504/65504 [==============================] - 2215s - loss: 1.7720 - acc: 0.9924 - val_loss: 0.0223 - val_acc: 0.9927\n",
      "Epoch 51/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7710 - acc: 0.9928Epoch 00050: val_loss did not improve\n",
      "65504/65504 [==============================] - 2214s - loss: 1.7711 - acc: 0.9928 - val_loss: 0.0223 - val_acc: 0.9927\n",
      "Epoch 52/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7704 - acc: 0.9925Epoch 00051: val_loss did not improve\n",
      "65504/65504 [==============================] - 2217s - loss: 1.7705 - acc: 0.9925 - val_loss: 0.0223 - val_acc: 0.9929\n",
      "Epoch 53/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7701 - acc: 0.9925Epoch 00052: val_loss improved from 0.02226 to 0.02222, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2219s - loss: 1.7701 - acc: 0.9925 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 54/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7695 - acc: 0.9925Epoch 00053: val_loss did not improve\n",
      "65504/65504 [==============================] - 2214s - loss: 1.7696 - acc: 0.9925 - val_loss: 0.0223 - val_acc: 0.9926\n",
      "Epoch 55/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7690 - acc: 0.9925Epoch 00054: val_loss improved from 0.02222 to 0.02217, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2217s - loss: 1.7690 - acc: 0.9925 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 56/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7685 - acc: 0.9926Epoch 00055: val_loss did not improve\n",
      "65504/65504 [==============================] - 2215s - loss: 1.7685 - acc: 0.9926 - val_loss: 0.0222 - val_acc: 0.9926\n",
      "Epoch 57/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7680 - acc: 0.9925Epoch 00056: val_loss did not improve\n",
      "65504/65504 [==============================] - 2212s - loss: 1.7680 - acc: 0.9925 - val_loss: 0.0222 - val_acc: 0.9926\n",
      "Epoch 58/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7676 - acc: 0.9926Epoch 00057: val_loss improved from 0.02217 to 0.02214, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2221s - loss: 1.7677 - acc: 0.9926 - val_loss: 0.0221 - val_acc: 0.9928\n",
      "Epoch 59/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7669 - acc: 0.9926Epoch 00058: val_loss did not improve\n",
      "65504/65504 [==============================] - 2221s - loss: 1.7669 - acc: 0.9926 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 60/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7662 - acc: 0.9925Epoch 00059: val_loss improved from 0.02214 to 0.02213, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2219s - loss: 1.7663 - acc: 0.9925 - val_loss: 0.0221 - val_acc: 0.9928\n",
      "Epoch 61/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7657 - acc: 0.9925Epoch 00060: val_loss did not improve\n",
      "65504/65504 [==============================] - 2220s - loss: 1.7658 - acc: 0.9925 - val_loss: 0.0224 - val_acc: 0.9927\n",
      "Epoch 62/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7656 - acc: 0.9925Epoch 00061: val_loss improved from 0.02213 to 0.02210, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2218s - loss: 1.7656 - acc: 0.9925 - val_loss: 0.0221 - val_acc: 0.9928\n",
      "Epoch 63/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7649 - acc: 0.9925Epoch 00062: val_loss improved from 0.02210 to 0.02201, saving model to ./cnn_140_rgb_corrected_full_finetune_decay_lr_0.050000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "65504/65504 [==============================] - 2225s - loss: 1.7649 - acc: 0.9925 - val_loss: 0.0220 - val_acc: 0.9927\n",
      "Epoch 64/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7645 - acc: 0.9926Epoch 00063: val_loss did not improve\n",
      "65504/65504 [==============================] - 2224s - loss: 1.7646 - acc: 0.9926 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 65/100\n",
      "65472/65504 [============================>.] - ETA: 1s - loss: 1.7639 - acc: 0.9924Epoch 00064: val_loss did not improve\n",
      "65504/65504 [==============================] - 2222s - loss: 1.7640 - acc: 0.9924 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 66/100\n",
      "10208/65504 [===>..........................] - ETA: 1797s - loss: 1.7650 - acc: 0.9921"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5380e26f6db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_checkpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_model_checkpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               nb_worker=2)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=2)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "done.\n",
      "Test score: 0.0258219342057\n",
      "Test accuracy: 0.992240888383\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
