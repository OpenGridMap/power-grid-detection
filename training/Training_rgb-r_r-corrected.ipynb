{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.cnn3 import cnn, cnn_regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=100\n",
    "batch_size=32\n",
    "input_shape=(140, 140, 3)\n",
    "\n",
    "name = 'cnn_140_rgb_corrected_lr_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 18944       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    204864      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    36928       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20777090\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = cnn_regularized(input_shape=input_shape, init='he_normal', l1=l1, l2=l2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=True)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/train_data.csv'\n",
    "validation_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/validation_data.csv'\n",
    "test_set_file = '/home/tanuj/Workspace/power-grid-detection/dataset/corrected/19/test_data.csv'\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.8536 - acc: 0.6617Epoch 00000: val_loss improved from inf to 0.62542, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 347s - loss: 2.8537 - acc: 0.6614 - val_loss: 0.6254 - val_acc: 0.6734\n",
      "Epoch 2/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.7861 - acc: 0.6999Epoch 00001: val_loss improved from 0.62542 to 0.39485, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 348s - loss: 2.7859 - acc: 0.7001 - val_loss: 0.3949 - val_acc: 0.8279\n",
      "Epoch 3/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.5580 - acc: 0.8644Epoch 00002: val_loss improved from 0.39485 to 0.17668, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.5575 - acc: 0.8647 - val_loss: 0.1767 - val_acc: 0.9476\n",
      "Epoch 4/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.3550 - acc: 0.9510Epoch 00003: val_loss improved from 0.17668 to 0.11472, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.3547 - acc: 0.9510 - val_loss: 0.1147 - val_acc: 0.9696\n",
      "Epoch 5/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.3143 - acc: 0.9628Epoch 00004: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.3141 - acc: 0.9628 - val_loss: 0.1211 - val_acc: 0.9674\n",
      "Epoch 6/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2993 - acc: 0.9658Epoch 00005: val_loss improved from 0.11472 to 0.10249, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2990 - acc: 0.9659 - val_loss: 0.1025 - val_acc: 0.9714\n",
      "Epoch 7/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2902 - acc: 0.9674Epoch 00006: val_loss improved from 0.10249 to 0.09478, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2899 - acc: 0.9675 - val_loss: 0.0948 - val_acc: 0.9714\n",
      "Epoch 8/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2812 - acc: 0.9694Epoch 00007: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2810 - acc: 0.9695 - val_loss: 0.0962 - val_acc: 0.9718\n",
      "Epoch 9/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2726 - acc: 0.9707Epoch 00008: val_loss improved from 0.09478 to 0.09067, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2724 - acc: 0.9708 - val_loss: 0.0907 - val_acc: 0.9723\n",
      "Epoch 10/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2665 - acc: 0.9705Epoch 00009: val_loss improved from 0.09067 to 0.08880, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 346s - loss: 2.2662 - acc: 0.9706 - val_loss: 0.0888 - val_acc: 0.9732\n",
      "Epoch 11/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2603 - acc: 0.9711Epoch 00010: val_loss improved from 0.08880 to 0.08837, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2601 - acc: 0.9711 - val_loss: 0.0884 - val_acc: 0.9718\n",
      "Epoch 12/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2545 - acc: 0.9704Epoch 00011: val_loss improved from 0.08837 to 0.08443, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2543 - acc: 0.9705 - val_loss: 0.0844 - val_acc: 0.9740\n",
      "Epoch 13/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2503 - acc: 0.9717Epoch 00012: val_loss improved from 0.08443 to 0.08415, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2501 - acc: 0.9718 - val_loss: 0.0841 - val_acc: 0.9749\n",
      "Epoch 14/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2432 - acc: 0.9730Epoch 00013: val_loss improved from 0.08415 to 0.08171, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2430 - acc: 0.9730 - val_loss: 0.0817 - val_acc: 0.9745\n",
      "Epoch 15/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2370 - acc: 0.9735Epoch 00014: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 2.2368 - acc: 0.9736 - val_loss: 0.0837 - val_acc: 0.9745\n",
      "Epoch 16/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2343 - acc: 0.9727Epoch 00015: val_loss improved from 0.08171 to 0.07743, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2341 - acc: 0.9728 - val_loss: 0.0774 - val_acc: 0.9754\n",
      "Epoch 17/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2291 - acc: 0.9742Epoch 00016: val_loss improved from 0.07743 to 0.07670, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 344s - loss: 2.2288 - acc: 0.9743 - val_loss: 0.0767 - val_acc: 0.9745\n",
      "Epoch 18/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2262 - acc: 0.9737Epoch 00017: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2259 - acc: 0.9738 - val_loss: 0.0773 - val_acc: 0.9745\n",
      "Epoch 19/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2211 - acc: 0.9742Epoch 00018: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2209 - acc: 0.9743 - val_loss: 0.0785 - val_acc: 0.9732\n",
      "Epoch 20/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2159 - acc: 0.9747Epoch 00019: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2157 - acc: 0.9748 - val_loss: 0.0789 - val_acc: 0.9754\n",
      "Epoch 21/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2132 - acc: 0.9752Epoch 00020: val_loss improved from 0.07670 to 0.07330, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.2131 - acc: 0.9752 - val_loss: 0.0733 - val_acc: 0.9745\n",
      "Epoch 22/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2063 - acc: 0.9754Epoch 00021: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2061 - acc: 0.9755 - val_loss: 0.0756 - val_acc: 0.9736\n",
      "Epoch 23/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.2033 - acc: 0.9752Epoch 00022: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.2032 - acc: 0.9752 - val_loss: 0.0766 - val_acc: 0.9732\n",
      "Epoch 24/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1985 - acc: 0.9762Epoch 00023: val_loss improved from 0.07330 to 0.07092, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1983 - acc: 0.9763 - val_loss: 0.0709 - val_acc: 0.9767\n",
      "Epoch 25/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1940 - acc: 0.9774Epoch 00024: val_loss improved from 0.07092 to 0.06994, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1938 - acc: 0.9775 - val_loss: 0.0699 - val_acc: 0.9780\n",
      "Epoch 26/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1906 - acc: 0.9775Epoch 00025: val_loss improved from 0.06994 to 0.06901, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1904 - acc: 0.9776 - val_loss: 0.0690 - val_acc: 0.9780\n",
      "Epoch 27/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1846 - acc: 0.9774Epoch 00026: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1844 - acc: 0.9775 - val_loss: 0.0691 - val_acc: 0.9771\n",
      "Epoch 28/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1815 - acc: 0.9775Epoch 00027: val_loss improved from 0.06901 to 0.06789, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1814 - acc: 0.9775 - val_loss: 0.0679 - val_acc: 0.9776\n",
      "Epoch 29/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1769 - acc: 0.9774Epoch 00028: val_loss improved from 0.06789 to 0.06739, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1767 - acc: 0.9774 - val_loss: 0.0674 - val_acc: 0.9780\n",
      "Epoch 30/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1738 - acc: 0.9773Epoch 00029: val_loss improved from 0.06739 to 0.06608, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1737 - acc: 0.9773 - val_loss: 0.0661 - val_acc: 0.9784\n",
      "Epoch 31/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1678 - acc: 0.9789Epoch 00030: val_loss did not improve\n",
      "10496/10496 [==============================] - 347s - loss: 2.1677 - acc: 0.9789 - val_loss: 0.0669 - val_acc: 0.9780\n",
      "Epoch 32/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1656 - acc: 0.9780Epoch 00031: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1655 - acc: 0.9781 - val_loss: 0.0673 - val_acc: 0.9758\n",
      "Epoch 33/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1591 - acc: 0.9797Epoch 00032: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1590 - acc: 0.9798 - val_loss: 0.0664 - val_acc: 0.9793\n",
      "Epoch 34/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1557 - acc: 0.9789Epoch 00033: val_loss improved from 0.06608 to 0.06367, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1556 - acc: 0.9789 - val_loss: 0.0637 - val_acc: 0.9789\n",
      "Epoch 35/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1530 - acc: 0.9790Epoch 00034: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1528 - acc: 0.9790 - val_loss: 0.0663 - val_acc: 0.9767\n",
      "Epoch 36/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1480 - acc: 0.9799Epoch 00035: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1479 - acc: 0.9800 - val_loss: 0.0637 - val_acc: 0.9806\n",
      "Epoch 37/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1444 - acc: 0.9803Epoch 00036: val_loss improved from 0.06367 to 0.06256, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 346s - loss: 2.1443 - acc: 0.9804 - val_loss: 0.0626 - val_acc: 0.9798\n",
      "Epoch 38/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1405 - acc: 0.9807Epoch 00037: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1403 - acc: 0.9808 - val_loss: 0.0627 - val_acc: 0.9793\n",
      "Epoch 39/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1366 - acc: 0.9805Epoch 00038: val_loss improved from 0.06256 to 0.06247, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1364 - acc: 0.9806 - val_loss: 0.0625 - val_acc: 0.9784\n",
      "Epoch 40/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1345 - acc: 0.9790Epoch 00039: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1343 - acc: 0.9790 - val_loss: 0.0715 - val_acc: 0.9767\n",
      "Epoch 41/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1301 - acc: 0.9793Epoch 00040: val_loss improved from 0.06247 to 0.06164, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1300 - acc: 0.9793 - val_loss: 0.0616 - val_acc: 0.9802\n",
      "Epoch 42/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1249 - acc: 0.9817Epoch 00041: val_loss improved from 0.06164 to 0.06008, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 348s - loss: 2.1247 - acc: 0.9817 - val_loss: 0.0601 - val_acc: 0.9815\n",
      "Epoch 43/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1222 - acc: 0.9813Epoch 00042: val_loss improved from 0.06008 to 0.05860, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1220 - acc: 0.9813 - val_loss: 0.0586 - val_acc: 0.9802\n",
      "Epoch 44/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1172 - acc: 0.9818Epoch 00043: val_loss did not improve\n",
      "10496/10496 [==============================] - 346s - loss: 2.1170 - acc: 0.9819 - val_loss: 0.0631 - val_acc: 0.9793\n",
      "Epoch 45/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1147 - acc: 0.9812Epoch 00044: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1145 - acc: 0.9812 - val_loss: 0.0591 - val_acc: 0.9820\n",
      "Epoch 46/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1098 - acc: 0.9808Epoch 00045: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 2.1097 - acc: 0.9808 - val_loss: 0.0686 - val_acc: 0.9780\n",
      "Epoch 47/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1061 - acc: 0.9814Epoch 00046: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.1060 - acc: 0.9814 - val_loss: 0.0643 - val_acc: 0.9793\n",
      "Epoch 48/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.1027 - acc: 0.9818Epoch 00047: val_loss improved from 0.05860 to 0.05739, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.1025 - acc: 0.9819 - val_loss: 0.0574 - val_acc: 0.9806\n",
      "Epoch 49/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0969 - acc: 0.9834Epoch 00048: val_loss did not improve\n",
      "10496/10496 [==============================] - 347s - loss: 2.0967 - acc: 0.9834 - val_loss: 0.0574 - val_acc: 0.9820\n",
      "Epoch 50/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0928 - acc: 0.9832Epoch 00049: val_loss improved from 0.05739 to 0.05710, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.0926 - acc: 0.9832 - val_loss: 0.0571 - val_acc: 0.9815\n",
      "Epoch 51/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0891 - acc: 0.9832Epoch 00050: val_loss improved from 0.05710 to 0.05460, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.0889 - acc: 0.9832 - val_loss: 0.0546 - val_acc: 0.9828\n",
      "Epoch 52/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0844 - acc: 0.9835Epoch 00051: val_loss did not improve\n",
      "10496/10496 [==============================] - 346s - loss: 2.0843 - acc: 0.9835 - val_loss: 0.0609 - val_acc: 0.9802\n",
      "Epoch 53/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0820 - acc: 0.9823Epoch 00052: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0819 - acc: 0.9824 - val_loss: 0.0579 - val_acc: 0.9806\n",
      "Epoch 54/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0799 - acc: 0.9824Epoch 00053: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0798 - acc: 0.9825 - val_loss: 0.0618 - val_acc: 0.9811\n",
      "Epoch 55/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0768 - acc: 0.9834Epoch 00054: val_loss improved from 0.05460 to 0.05353, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.0767 - acc: 0.9834 - val_loss: 0.0535 - val_acc: 0.9833\n",
      "Epoch 56/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0747 - acc: 0.9821Epoch 00055: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0745 - acc: 0.9822 - val_loss: 0.0542 - val_acc: 0.9820\n",
      "Epoch 57/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0676 - acc: 0.9840Epoch 00056: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0674 - acc: 0.9841 - val_loss: 0.0587 - val_acc: 0.9815\n",
      "Epoch 58/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0637 - acc: 0.9849Epoch 00057: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 2.0635 - acc: 0.9849 - val_loss: 0.0547 - val_acc: 0.9837\n",
      "Epoch 59/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0606 - acc: 0.9838Epoch 00058: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 2.0605 - acc: 0.9839 - val_loss: 0.0556 - val_acc: 0.9820\n",
      "Epoch 60/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0589 - acc: 0.9846Epoch 00059: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0587 - acc: 0.9847 - val_loss: 0.0570 - val_acc: 0.9842\n",
      "Epoch 61/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0550 - acc: 0.9843Epoch 00060: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0548 - acc: 0.9844 - val_loss: 0.0556 - val_acc: 0.9828\n",
      "Epoch 62/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0499 - acc: 0.9838Epoch 00061: val_loss improved from 0.05353 to 0.05230, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 346s - loss: 2.0498 - acc: 0.9838 - val_loss: 0.0523 - val_acc: 0.9842\n",
      "Epoch 63/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0445 - acc: 0.9844Epoch 00062: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0444 - acc: 0.9845 - val_loss: 0.0530 - val_acc: 0.9846\n",
      "Epoch 64/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0404 - acc: 0.9859Epoch 00063: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0403 - acc: 0.9859 - val_loss: 0.0540 - val_acc: 0.9846\n",
      "Epoch 65/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0363 - acc: 0.9861Epoch 00064: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0362 - acc: 0.9862 - val_loss: 0.0606 - val_acc: 0.9820\n",
      "Epoch 66/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0349 - acc: 0.9852Epoch 00065: val_loss did not improve\n",
      "10496/10496 [==============================] - 345s - loss: 2.0348 - acc: 0.9852 - val_loss: 0.0578 - val_acc: 0.9846\n",
      "Epoch 67/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0314 - acc: 0.9847Epoch 00066: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0313 - acc: 0.9848 - val_loss: 0.0665 - val_acc: 0.9815\n",
      "Epoch 68/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0271 - acc: 0.9868Epoch 00067: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0270 - acc: 0.9869 - val_loss: 0.0530 - val_acc: 0.9859\n",
      "Epoch 69/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0206 - acc: 0.9881Epoch 00068: val_loss improved from 0.05230 to 0.04961, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 2.0205 - acc: 0.9882 - val_loss: 0.0496 - val_acc: 0.9846\n",
      "Epoch 70/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0190 - acc: 0.9864Epoch 00069: val_loss did not improve\n",
      "10496/10496 [==============================] - 345s - loss: 2.0188 - acc: 0.9865 - val_loss: 0.0498 - val_acc: 0.9846\n",
      "Epoch 71/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0169 - acc: 0.9865Epoch 00070: val_loss did not improve\n",
      "10496/10496 [==============================] - 345s - loss: 2.0168 - acc: 0.9866 - val_loss: 0.0531 - val_acc: 0.9837\n",
      "Epoch 72/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0131 - acc: 0.9862Epoch 00071: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0130 - acc: 0.9863 - val_loss: 0.0497 - val_acc: 0.9828\n",
      "Epoch 73/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0094 - acc: 0.9863Epoch 00072: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0093 - acc: 0.9864 - val_loss: 0.0562 - val_acc: 0.9837\n",
      "Epoch 74/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0043 - acc: 0.9869Epoch 00073: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0042 - acc: 0.9869 - val_loss: 0.0537 - val_acc: 0.9837\n",
      "Epoch 75/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 2.0006 - acc: 0.9883Epoch 00074: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 2.0005 - acc: 0.9884 - val_loss: 0.0498 - val_acc: 0.9850\n",
      "Epoch 76/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9978 - acc: 0.9880Epoch 00075: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9977 - acc: 0.9880 - val_loss: 0.0538 - val_acc: 0.9842\n",
      "Epoch 77/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9939 - acc: 0.9870Epoch 00076: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9938 - acc: 0.9870 - val_loss: 0.0687 - val_acc: 0.9815\n",
      "Epoch 78/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9920 - acc: 0.9881Epoch 00077: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9919 - acc: 0.9881 - val_loss: 0.0562 - val_acc: 0.9842\n",
      "Epoch 79/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9870 - acc: 0.9888Epoch 00078: val_loss improved from 0.04961 to 0.04877, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 1.9869 - acc: 0.9889 - val_loss: 0.0488 - val_acc: 0.9842\n",
      "Epoch 80/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9852 - acc: 0.9877Epoch 00079: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 1.9851 - acc: 0.9877 - val_loss: 0.0506 - val_acc: 0.9859\n",
      "Epoch 81/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9783 - acc: 0.9887Epoch 00080: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 1.9783 - acc: 0.9888 - val_loss: 0.0534 - val_acc: 0.9859\n",
      "Epoch 82/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9780 - acc: 0.9877Epoch 00081: val_loss improved from 0.04877 to 0.04866, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 1.9779 - acc: 0.9877 - val_loss: 0.0487 - val_acc: 0.9855\n",
      "Epoch 83/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9744 - acc: 0.9882Epoch 00082: val_loss improved from 0.04866 to 0.04810, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 1.9743 - acc: 0.9883 - val_loss: 0.0481 - val_acc: 0.9859\n",
      "Epoch 84/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9705 - acc: 0.9894Epoch 00083: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9704 - acc: 0.9894 - val_loss: 0.0563 - val_acc: 0.9846\n",
      "Epoch 85/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9657 - acc: 0.9898Epoch 00084: val_loss improved from 0.04810 to 0.04755, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 345s - loss: 1.9656 - acc: 0.9898 - val_loss: 0.0476 - val_acc: 0.9855\n",
      "Epoch 86/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9622 - acc: 0.9895Epoch 00085: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9621 - acc: 0.9895 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 87/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9592 - acc: 0.9893Epoch 00086: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9591 - acc: 0.9893 - val_loss: 0.0511 - val_acc: 0.9846\n",
      "Epoch 88/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9566 - acc: 0.9895Epoch 00087: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 1.9566 - acc: 0.9895 - val_loss: 0.0477 - val_acc: 0.9855\n",
      "Epoch 89/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9540 - acc: 0.9893Epoch 00088: val_loss improved from 0.04755 to 0.04707, saving model to ./cnn_140_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5\n",
      "10496/10496 [==============================] - 346s - loss: 1.9539 - acc: 0.9893 - val_loss: 0.0471 - val_acc: 0.9855\n",
      "Epoch 90/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9514 - acc: 0.9895Epoch 00089: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9513 - acc: 0.9895 - val_loss: 0.0498 - val_acc: 0.9846\n",
      "Epoch 91/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9451 - acc: 0.9903Epoch 00090: val_loss did not improve\n",
      "10496/10496 [==============================] - 343s - loss: 1.9450 - acc: 0.9903 - val_loss: 0.0492 - val_acc: 0.9850\n",
      "Epoch 92/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9415 - acc: 0.9897Epoch 00091: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9414 - acc: 0.9897 - val_loss: 0.0483 - val_acc: 0.9850\n",
      "Epoch 93/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9402 - acc: 0.9898Epoch 00092: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9402 - acc: 0.9898 - val_loss: 0.0479 - val_acc: 0.9859\n",
      "Epoch 94/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9346 - acc: 0.9907Epoch 00093: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9345 - acc: 0.9908 - val_loss: 0.0490 - val_acc: 0.9846\n",
      "Epoch 95/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9329 - acc: 0.9905Epoch 00094: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9328 - acc: 0.9906 - val_loss: 0.0525 - val_acc: 0.9842\n",
      "Epoch 96/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9274 - acc: 0.9910Epoch 00095: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9273 - acc: 0.9910 - val_loss: 0.0518 - val_acc: 0.9859\n",
      "Epoch 97/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9259 - acc: 0.9913Epoch 00096: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9258 - acc: 0.9913 - val_loss: 0.0492 - val_acc: 0.9850\n",
      "Epoch 98/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9218 - acc: 0.9916Epoch 00097: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9217 - acc: 0.9916 - val_loss: 0.0517 - val_acc: 0.9859\n",
      "Epoch 99/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9205 - acc: 0.9910Epoch 00098: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9204 - acc: 0.9910 - val_loss: 0.0492 - val_acc: 0.9850\n",
      "Epoch 100/100\n",
      "10464/10496 [============================>.] - ETA: 1s - loss: 1.9156 - acc: 0.9916Epoch 00099: val_loss did not improve\n",
      "10496/10496 [==============================] - 344s - loss: 1.9155 - acc: 0.9916 - val_loss: 0.0487 - val_acc: 0.9859\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=2)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
