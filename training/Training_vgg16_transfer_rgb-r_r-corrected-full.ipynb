{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpql17u6/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpql17u6/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5110)\n",
      "C:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.dataset.data_generator import DataGenerator\n",
    "from models.vgg import vgg16\n",
    "from utils.training.callbacks import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "l1 = 0.00001\n",
    "l2 = 0.00001\n",
    "dropout = 0.5\n",
    "n_epochs=100\n",
    "batch_size=32\n",
    "input_shape=(224, 224, 3)\n",
    "# weights='vgg16_transger_224_rgb_corrected_lr_0.005000_sgd_he_normal__l1_0.000010_l2_0.000010_dropout_0.500000_r_training_weights_best.hdf5'\n",
    "\n",
    "name = 'cnn_224_rgb_corrected_full_lr_%f_sgd_he_normal__l1_%f_l2_%f_dropout_%f_r' % (lr, l1, l2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 2)             8194        fc2[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "# model = cnn(input_shape=input_shape, init='he_normal')\n",
    "model = vgg16(input_shape=input_shape, vgg_transfer=True, l1=l1, l2=l2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=lr, clipnorm=4., nesterov=True)\n",
    "# optimizer = Nadam(lr=lr)\n",
    "# optimizer = RMSprop(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')\n",
    "\n",
    "logger = Logger('%s_training_batch.log' % name, append=True)\n",
    "csv_logger = CSVLogger('%s_training.log' % name, append=True)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)\n",
    "\n",
    "current_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_current.hdf5\" % name), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_set_file = config.corrected_train_data_file\n",
    "validation_set_file = config.corrected_validation_data_file\n",
    "test_set_file = config.corrected_test_data_file\n",
    "\n",
    "train_data_gen = DataGenerator(dataset_file=train_set_file, batch_size=batch_size, vgg=True)\n",
    "validation_data_gen = DataGenerator(dataset_file=validation_set_file, batch_size=batch_size, vgg=True)\n",
    "test_data_gen = DataGenerator(dataset_file=test_set_file, batch_size=batch_size, vgg=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpuv4ze7/2dadd095cd2b794690b21e4d38324cd6.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpuv4ze7/2dadd095cd2b794690b21e4d38324cd6.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpq3se2b/beb1185d39dc986bbbccafdcde230b65.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpq3se2b/beb1185d39dc986bbbccafdcde230b65.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "mod.cu(393): warning C4477: 'printf' : format string '%d' requires an argument of type 'int', but variadic argument 2 has type 'std::size_t'\n",
      "mod.cu(393): note: consider using '%zd' in the format string\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpgdrjza/c7c7f61832c0a2a91453e6c0b2381b3b.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpgdrjza/c7c7f61832c0a2a91453e6c0b2381b3b.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmppw_x50/ef5673747c99044f59681d9ee3ac8b53.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmppw_x50/ef5673747c99044f59681d9ee3ac8b53.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4erqrf/e378fa671673808948d802c84c5474c1.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4erqrf/e378fa671673808948d802c84c5474c1.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp7hpwxy/53fe98c12d1e3ef91e7cadb9ef0de453.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp7hpwxy/53fe98c12d1e3ef91e7cadb9ef0de453.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4u5sts/63a4428243fb361a51803665de59edb6.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4u5sts/63a4428243fb361a51803665de59edb6.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmph9gz1e/feba001387297c762217dcfc251c11ef.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmph9gz1e/feba001387297c762217dcfc251c11ef.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmph8ot_a/826c6ab96bfe69bdc456953bde01fc32.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmph8ot_a/826c6ab96bfe69bdc456953bde01fc32.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpi0p2am/871c51ee977ba1fb8766e4f4db105247.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpi0p2am/871c51ee977ba1fb8766e4f4db105247.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpwaur4s/ee4c467d536b548f7d94eade90ae839e.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpwaur4s/ee4c467d536b548f7d94eade90ae839e.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpoasoxc/3c6c04e3068ff9379cd45464022356de.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpoasoxc/3c6c04e3068ff9379cd45464022356de.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpj3hot5/3d67d0fe5761a4be480eecf6fd47a3a7.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpj3hot5/3d67d0fe5761a4be480eecf6fd47a3a7.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp539ggx/225f99c08747de319a94c9336ee203aa.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp539ggx/225f99c08747de319a94c9336ee203aa.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpnawbn7/f9ab04cfb23018dc03314f4e50502dd8.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpnawbn7/f9ab04cfb23018dc03314f4e50502dd8.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmps6z3vm/1f77676baa319f8544e1429675dadf3e.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmps6z3vm/1f77676baa319f8544e1429675dadf3e.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4kdyua/c8f5e98460d42f69bb22e071147735f8.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmp4kdyua/c8f5e98460d42f69bb22e071147735f8.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpvbw_2m/7c9069cbf2b9b8bac41f69eb285e5c78.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpvbw_2m/7c9069cbf2b9b8bac41f69eb285e5c78.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpkjixui/a3d157572777a271a5f162093604665b.lib and object C:/Users/Tanuj/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpkjixui/a3d157572777a271a5f162093604665b.exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 411041792 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuElemwise{Abs,no_inplace}(fc1_W)\nToposort index: 99\nInputs types: [CudaNdarrayType(float32, matrix)]\nInputs shapes: [(25088, 4096)]\nInputs strides: [(4096, 1)]\nInputs values: ['not shown']\nOutputs clients: [[GpuCAReduce{add}{1,1}(GpuElemwise{Abs,no_inplace}.0)]]\n\nDebugprint of the apply node: \nGpuElemwise{Abs,no_inplace} [id A] <CudaNdarrayType(float32, matrix)> ''   \n |fc1_W [id B] <CudaNdarrayType(float32, matrix)>\n\nStorage map footprint:\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 224, 224, 64), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 224, 224, 64), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (25088, 4096), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 224, 224), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - fc1_W, Shared Input, Shape: (25088, 4096), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 224, 224), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 112, 112, 128), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 112, 112), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (32, 112, 112, 128), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 112, 112), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 112, 112), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (4096, 4096), ElemSize: 4 Byte(s), TotalSize: 67108864 Byte(s)\n - fc2_W, Shared Input, Shape: (4096, 4096), ElemSize: 4 Byte(s), TotalSize: 67108864 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 56, 56), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 28, 28), ElemSize: 4 Byte(s), TotalSize: 25690112 Byte(s)\n - input_1, Input, Shape: (32L, 224L, 224L, 3L), ElemSize: 4 Byte(s), TotalSize: 19267584 Byte(s)\n - GpuContiguous.0, Shape: (32, 3, 224, 224), ElemSize: 4 Byte(s), TotalSize: 19267584 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv1_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv3_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block4_conv3_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv2_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block4_conv2_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 512), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - block4_conv1_W, Shared Input, Shape: (3, 3, 256, 512), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - GpuDnnPool{mode='max'}.0, Shape: (32, 512, 7, 7), ElemSize: 4 Byte(s), TotalSize: 3211264 Byte(s)\n - GpuReshape{2}.0, Shape: (32, 25088), ElemSize: 4 Byte(s), TotalSize: 3211264 Byte(s)\n - GpuContiguous.0, Shape: (256, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - GpuContiguous.0, Shape: (256, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - block3_conv2_W, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - block3_conv3_W, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - GpuContiguous.0, Shape: (256, 128, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 128, 256), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - block3_conv1_W, Shared Input, Shape: (3, 3, 128, 256), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - GpuContiguous.0, Shape: (128, 128, 3, 3), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 128, 128), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - block2_conv2_W, Shared Input, Shape: (3, 3, 128, 128), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{(i0 + Abs(i0))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - if{inplace,gpu}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}.0, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - block2_conv1_W, Shared Input, Shape: (3, 3, 64, 128), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - GpuContiguous.0, Shape: (128, 64, 3, 3), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 64, 128), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - block1_conv2_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - GpuContiguous.0, Shape: (64, 64, 3, 3), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (4096, 2), ElemSize: 4 Byte(s), TotalSize: 32768 Byte(s)\n - predictions_W, Shared Input, Shape: (4096, 2), ElemSize: 4 Byte(s), TotalSize: 32768 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - fc2_b, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - fc1_b, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - block1_conv1_W, Shared Input, Shape: (3, 3, 3, 64), ElemSize: 4 Byte(s), TotalSize: 6912 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 3, 64), ElemSize: 4 Byte(s), TotalSize: 6912 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv2_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv2_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv1_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv1_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv2_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv1_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv3_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block2_conv1_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - block2_conv2_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - predictions_target, Input, Shape: (32L, 2L), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuFromHost.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - block1_conv2_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - block1_conv1_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{clip,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuSoftmaxWithBias.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - predictions_sample_weights, Input, Shape: (32L,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - GpuFromHost.0, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[  1   1   1 512]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[  1   1   1 256]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[  1   1   1 128]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ 1  1  1 64]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(2L,) of 2}, Shape: (2L,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(2L,) of 0}, Shape: (2L,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i0 * i3 * i4) // (-(i0 * i5))), i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{256}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{512}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - predictions_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[  1.99999995e-05]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.5]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{4.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999975e-06]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  1.00000001e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 4.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  1.99999995e-05]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 4.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99999988]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{inf}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuCAReduce{add}{1}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuCAReduce{add}{1}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 2.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 4.]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - keras_learning_phase, Input, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 4842301090.0 Byte(s) 4.510 GB\n TotalSize inputs: 1093786782.0 Byte(s) 1.019 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5380e26f6db3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model_checkpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_model_checkpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                               nb_worker=2)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1506\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1507\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1509\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1265\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tanuj\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 411041792 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuElemwise{Abs,no_inplace}(fc1_W)\nToposort index: 99\nInputs types: [CudaNdarrayType(float32, matrix)]\nInputs shapes: [(25088, 4096)]\nInputs strides: [(4096, 1)]\nInputs values: ['not shown']\nOutputs clients: [[GpuCAReduce{add}{1,1}(GpuElemwise{Abs,no_inplace}.0)]]\n\nDebugprint of the apply node: \nGpuElemwise{Abs,no_inplace} [id A] <CudaNdarrayType(float32, matrix)> ''   \n |fc1_W [id B] <CudaNdarrayType(float32, matrix)>\n\nStorage map footprint:\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 224, 224, 64), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 224, 224, 64), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (25088, 4096), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 224, 224), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - fc1_W, Shared Input, Shape: (25088, 4096), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 224, 224), ElemSize: 4 Byte(s), TotalSize: 411041792 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 112, 112, 128), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 112, 112), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (32, 112, 112, 128), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 112, 112), ElemSize: 4 Byte(s), TotalSize: 205520896 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 56, 56), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 56, 56, 256), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - GpuContiguous.0, Shape: (32, 64, 112, 112), ElemSize: 4 Byte(s), TotalSize: 102760448 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (4096, 4096), ElemSize: 4 Byte(s), TotalSize: 67108864 Byte(s)\n - fc2_W, Shared Input, Shape: (4096, 4096), ElemSize: 4 Byte(s), TotalSize: 67108864 Byte(s)\n - GpuContiguous.0, Shape: (32, 128, 56, 56), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 28, 28, 512), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 28, 28), ElemSize: 4 Byte(s), TotalSize: 51380224 Byte(s)\n - GpuContiguous.0, Shape: (32, 256, 28, 28), ElemSize: 4 Byte(s), TotalSize: 25690112 Byte(s)\n - input_1, Input, Shape: (32L, 224L, 224L, 3L), ElemSize: 4 Byte(s), TotalSize: 19267584 Byte(s)\n - GpuContiguous.0, Shape: (32, 3, 224, 224), ElemSize: 4 Byte(s), TotalSize: 19267584 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 14, 14, 512), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (32, 512, 14, 14), ElemSize: 4 Byte(s), TotalSize: 12845056 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 512, 3, 3), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv1_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv3_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block4_conv3_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block5_conv2_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - block4_conv2_W, Shared Input, Shape: (3, 3, 512, 512), ElemSize: 4 Byte(s), TotalSize: 9437184 Byte(s)\n - GpuContiguous.0, Shape: (512, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 512), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - block4_conv1_W, Shared Input, Shape: (3, 3, 256, 512), ElemSize: 4 Byte(s), TotalSize: 4718592 Byte(s)\n - GpuDnnPool{mode='max'}.0, Shape: (32, 512, 7, 7), ElemSize: 4 Byte(s), TotalSize: 3211264 Byte(s)\n - GpuReshape{2}.0, Shape: (32, 25088), ElemSize: 4 Byte(s), TotalSize: 3211264 Byte(s)\n - GpuContiguous.0, Shape: (256, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - GpuContiguous.0, Shape: (256, 256, 3, 3), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - block3_conv2_W, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - block3_conv3_W, Shared Input, Shape: (3, 3, 256, 256), ElemSize: 4 Byte(s), TotalSize: 2359296 Byte(s)\n - GpuContiguous.0, Shape: (256, 128, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 128, 256), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - block3_conv1_W, Shared Input, Shape: (3, 3, 128, 256), ElemSize: 4 Byte(s), TotalSize: 1179648 Byte(s)\n - GpuContiguous.0, Shape: (128, 128, 3, 3), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 128, 128), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - block2_conv2_W, Shared Input, Shape: (3, 3, 128, 128), ElemSize: 4 Byte(s), TotalSize: 589824 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{(i0 + Abs(i0))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - if{inplace,gpu}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}.0, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - block2_conv1_W, Shared Input, Shape: (3, 3, 64, 128), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - GpuContiguous.0, Shape: (128, 64, 3, 3), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 64, 128), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - block1_conv2_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - GpuContiguous.0, Shape: (64, 64, 3, 3), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (4096, 2), ElemSize: 4 Byte(s), TotalSize: 32768 Byte(s)\n - predictions_W, Shared Input, Shape: (4096, 2), ElemSize: 4 Byte(s), TotalSize: 32768 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - fc2_b, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - fc1_b, Shared Input, Shape: (4096,), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - block1_conv1_W, Shared Input, Shape: (3, 3, 3, 64), ElemSize: 4 Byte(s), TotalSize: 6912 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (3, 3, 3, 64), ElemSize: 4 Byte(s), TotalSize: 6912 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv2_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv2_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block4_conv1_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - block5_conv1_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv2_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv1_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block3_conv3_b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - block2_conv1_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - block2_conv2_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - predictions_target, Input, Shape: (32L, 2L), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuFromHost.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - block1_conv2_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - block1_conv1_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{clip,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - GpuSoftmaxWithBias.0, Shape: (32, 2), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - predictions_sample_weights, Input, Shape: (32L,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - GpuFromHost.0, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4L,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[  1   1   1 512]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[  1   1   1 256]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[  1   1   1 128]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ 1  1  1 64]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(2L,) of 2}, Shape: (2L,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(2L,) of 0}, Shape: (2L,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i0 * i3 * i4) // (-(i0 * i5))), i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{256}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{int_div,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{512}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - predictions_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[  1.99999995e-05]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.5]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{4.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999975e-06]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  1.00000001e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 4.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  1.99999995e-05]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 4.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99999988]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{inf}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuCAReduce{add}{1}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuCAReduce{add}{1}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 2.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 4.]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - keras_learning_phase, Input, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 4842301090.0 Byte(s) 4.510 GB\n TotalSize inputs: 1093786782.0 Byte(s) 1.019 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, logger, best_model_checkpointer, current_model_checkpointer],\n",
    "                              nb_worker=2)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
